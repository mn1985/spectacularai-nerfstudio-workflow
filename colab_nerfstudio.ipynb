{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726d1f9e",
   "metadata": {},
   "source": [
    "# oak-d Ã— spectacularAI Ã— nerfstudio Google Colab ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€oak-dã§æ’®å½±ã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆspectacularAIå½¢å¼ï¼‰ã‚’Google Colabã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€nerfstudioã§å­¦ç¿’ãƒ»å¯è¦–åŒ–ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¾ã§ã®ä¸€é€£ã®æ‰‹é †ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## æ¦‚è¦\n",
    "1. **Colabç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—** - PyTorch(GPUå¯¾å¿œ)ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨GPUè©³ç´°ç¢ºèª\n",
    "2. **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** - processed.zipã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»å±•é–‹ãƒ»ãƒ‘ã‚¹ä¿®æ­£\n",
    "3. **nerfstudioã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«** - nerfstudioã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨å‹•ä½œç¢ºèª\n",
    "4. **ãƒ‡ãƒ¼ã‚¿ç¢ºèª** - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æ§‹é€ ç¢ºèª\n",
    "5. **å­¦ç¿’å®Ÿè¡Œ** - nerfstudioã§ã®å­¦ç¿’ã¨GPUä½¿ç”¨çŠ¶æ³ç›£è¦–ãƒ»é€²æ—è¡¨ç¤º\n",
    "6. **çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰** - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«(.ckpt)ã¨config.ymlã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "- ãƒ­ãƒ¼ã‚«ãƒ«ã§ `sai-cli process --format nerfstudio` ã«ã‚ˆã‚Š processed/ ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆæ¸ˆã¿\n",
    "- processed.zip ãƒ•ã‚¡ã‚¤ãƒ«ãŒæº–å‚™æ¸ˆã¿\n",
    "\n",
    "## ä¸»ãªæ”¹å–„ç‚¹\n",
    "- ğŸ”§ **Windowsäº’æ›æ€§**: ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã®è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½\n",
    "- ğŸ“Š **GPUç›£è¦–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º\n",
    "- âš¡ **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: å„æ®µéšã§ã®è©³ç´°ãªã‚¨ãƒ©ãƒ¼è¨ºæ–­\n",
    "- ğŸ’¾ **ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†**: ã‚µã‚¤ã‚ºç¢ºèªä»˜ãã®é¸æŠçš„ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "- â±ï¸ **é€²æ—è¡¨ç¤º**: çµŒéæ™‚é–“ã¨ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®ç›£è¦–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779981cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Colabç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "print(\"=== Pythonãƒ»GPUç’°å¢ƒç¢ºèª ===\")\n",
    "!python --version\n",
    "!nvidia-smi  # GPUç¢ºèª\n",
    "\n",
    "print(\"\\n=== ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ===\")\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# GPUå¯¾å¿œPyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "print(\"PyTorch(GPUå¯¾å¿œ)ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# nerfstudioã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "print(\"nerfstudioã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
    "!pip install nerfstudio\n",
    "\n",
    "print(\"\\n=== GPUåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ ===\")\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(\"âœ… GPUå­¦ç¿’ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "else:\n",
    "    print(\"âŒ GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆCPUã§å­¦ç¿’ã•ã‚Œã¾ã™ï¼‰\")\n",
    "    print(\"ğŸ’¡ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  â†’ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ â†’ GPU(T4)ã‚’é¸æŠã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ãƒ‡ãƒ¼ã‚¿ã‚’Google Colabã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "# processed/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’zipãƒ•ã‚¡ã‚¤ãƒ«ã«ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\n",
    "# ãƒ­ãƒ¼ã‚«ãƒ«ã§: processed ãƒ•ã‚©ãƒ«ãƒ€ã‚’å³ã‚¯ãƒªãƒƒã‚¯ â†’ åœ§ç¸® â†’ processed.zip\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "print(\"=== ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ===\")\n",
    "print(\"processed.zip ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆNerfStudioå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ï¼‰\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    print(\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "    exit()\n",
    "\n",
    "# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"ğŸ“¦ {filename} ã‚’å±•é–‹ä¸­...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            print(f\"âœ… {filename} ã‚’å±•é–‹ã—ã¾ã—ãŸ\")\n",
    "            os.remove(filename)  # zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            continue\n",
    "\n",
    "# Windowsãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã®å•é¡Œã‚’ä¿®æ­£\n",
    "print(\"\\n=== ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ä¿®æ­£ ===\")\n",
    "if os.path.exists('processed'):\n",
    "    # transforms.jsonã®ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä¿®æ­£\n",
    "    transforms_path = 'processed/transforms.json'\n",
    "    if os.path.exists(transforms_path):\n",
    "        try:\n",
    "            with open(transforms_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            path_fixed = False\n",
    "            # ã™ã¹ã¦ã®ãƒ‘ã‚¹ã‚’ä¿®æ­£\n",
    "            if 'frames' in data:\n",
    "                for frame in data['frames']:\n",
    "                    if 'file_path' in frame and '\\\\' in frame['file_path']:\n",
    "                        # ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«å¤‰æ›\n",
    "                        frame['file_path'] = frame['file_path'].replace('\\\\', '/')\n",
    "                        path_fixed = True\n",
    "            \n",
    "            if path_fixed:\n",
    "                # ä¿®æ­£ã—ãŸJSONã‚’ä¿å­˜\n",
    "                with open(transforms_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(data, f, indent=2)\n",
    "                print(\"âœ… transforms.json ã®ãƒ‘ã‚¹ã‚’ä¿®æ­£ã—ã¾ã—ãŸ\")\n",
    "            else:\n",
    "                print(\"âœ“ transforms.json ã®ãƒ‘ã‚¹ã¯æ­£å¸¸ã§ã™\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ãƒ‘ã‚¹ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ transforms.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(\"âŒ processed/ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ç¢ºèª\n",
    "print(\"\\n=== ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç¢ºèª ===\")\n",
    "!ls -la\n",
    "if os.path.exists('processed'):\n",
    "    print(\"\\n=== processed/ å†…å®¹ç¢ºèª ===\")\n",
    "    !ls -la processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86949505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. nerfstudioå‹•ä½œç¢ºèª\n",
    "print(\"=== nerfstudioå‹•ä½œç¢ºèª ===\")\n",
    "\n",
    "# nerfstudioã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ\n",
    "import nerfstudio\n",
    "print(\"âœ“ nerfstudio ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã—ãŸ\")\n",
    "\n",
    "# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª\n",
    "!pip show nerfstudio | grep Version\n",
    "\n",
    "# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ç¢ºèª\n",
    "print(\"\\n=== nerfstudioã‚³ãƒãƒ³ãƒ‰ç¢ºèª ===\")\n",
    "!ns-train --help | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
    "print(\"=== ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª ===\")\n",
    "!find processed -type f | head -20\n",
    "\n",
    "print(\"\\n=== å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª ===\")\n",
    "import os\n",
    "import json\n",
    "\n",
    "# transforms.jsonã®å­˜åœ¨ç¢ºèªã¨å†…å®¹ç¢ºèª\n",
    "if os.path.exists('processed/transforms.json'):\n",
    "    print(\"âœ“ transforms.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "    \n",
    "    # transforms.jsonã®å†…å®¹ç¢ºèª\n",
    "    try:\n",
    "        with open('processed/transforms.json', 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if 'frames' in data:\n",
    "            frame_count = len(data['frames'])\n",
    "            print(f\"  ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}\")\n",
    "            \n",
    "            # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèª\n",
    "            if frame_count > 0:\n",
    "                sample_path = data['frames'][0].get('file_path', '')\n",
    "                print(f\"  ã‚µãƒ³ãƒ—ãƒ«ãƒ‘ã‚¹: {sample_path}\")\n",
    "                \n",
    "                # ãƒ‘ã‚¹å½¢å¼ã®ç¢ºèª\n",
    "                if '\\\\' in sample_path:\n",
    "                    print(\"  âš ï¸ Windowsãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆè¦ä¿®æ­£ï¼‰\")\n",
    "                else:\n",
    "                    print(\"  âœ“ ãƒ‘ã‚¹å½¢å¼ã¯æ­£å¸¸ã§ã™\")\n",
    "        else:\n",
    "            print(\"  âŒ framesãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ transforms.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "else:\n",
    "    print(\"âŒ transforms.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª\n",
    "if os.path.exists('processed/images'):\n",
    "    all_files = os.listdir('processed/images')\n",
    "    jpg_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "    png_files = [f for f in all_files if f.lower().endswith('.png')]\n",
    "    \n",
    "    print(f\"âœ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã« {len(jpg_files)} æšã®JPGç”»åƒã¨ {len(png_files)} æšã®PNGç”»åƒãŒã‚ã‚Šã¾ã™\")\n",
    "    \n",
    "    if jpg_files:\n",
    "        print(f\"  ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ: {jpg_files[0]}\")\n",
    "    \n",
    "    total_images = len(jpg_files) + len(png_files)\n",
    "    if total_images > 0:\n",
    "        print(\"âœ… å­¦ç¿’æº–å‚™å®Œäº†ï¼\")\n",
    "        if total_images < 10:\n",
    "            print(\"âš ï¸ ç”»åƒæ•°ãŒå°‘ãªã„ãŸã‚ã€å­¦ç¿’çµæœã®å“è³ªãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "    else:\n",
    "        print(\"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(\"âŒ images ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ãã®ä»–ã®é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª\n",
    "additional_files = ['processed/sparse_pc.ply', 'processed/colmap']\n",
    "for file_path in additional_files:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"âœ“ {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "    else:\n",
    "        print(f\"  {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Nerfstudioå­¦ç¿’ï¼‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°è¡¨ç¤ºï¼‹ä¸­æ–­æ™‚ä¿å­˜\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "print(\"=== å­¦ç¿’é–‹å§‹ ===\")\n",
    "print(\"âš ï¸ å­¦ç¿’ã«ã¯æ•°åˆ†ã€œæ•°ååˆ†ã‹ã‹ã‚Šã¾ã™\")\n",
    "print(\"ğŸ’¡ Ctrl+C ã§ä¸­æ–­å¯èƒ½ã§ã™ï¼ˆé€”ä¸­çµæœã¯ä¿å­˜ã•ã‚Œã¾ã™ï¼‰\\n\")\n",
    "\n",
    "# GPUç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰\n",
    "def monitor_gpu():\n",
    "    \"\"\"GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å®šæœŸçš„ã«è¡¨ç¤º\"\"\"\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        while True:\n",
    "            try:\n",
    "                memory_used = torch.cuda.memory_allocated(0) / 1024**3\n",
    "                memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "                print(f\"ğŸ“Š GPU Memory: {memory_used:.1f}/{memory_total:.1f} GB\", end='\\r')\n",
    "                time.sleep(30)  # 30ç§’ã”ã¨ã«æ›´æ–°\n",
    "            except:\n",
    "                break\n",
    "\n",
    "# å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰\n",
    "cmd = [\n",
    "    \"ns-train\",\n",
    "    \"nerfacto\",\n",
    "    \"--pipeline.datamanager.data\", \"processed/\",\n",
    "    \"--output-dir\", \"outputs/\",\n",
    "    \"--max-num-iterations\", \"30000\",         # æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "    \"--steps-per-save\", \"500\",               # 500ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è‡ªå‹•ä¿å­˜\n",
    "    \"--logging.steps-per-log\", \"10\"          # ãƒ­ã‚°è¡¨ç¤ºé–“éš”\n",
    "]\n",
    "\n",
    "print(f\"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}\\n\")\n",
    "\n",
    "# GPUç›£è¦–é–‹å§‹\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    monitor_thread = threading.Thread(target=monitor_gpu, daemon=True)\n",
    "    monitor_thread.start()\n",
    "\n",
    "start_time = time.time()\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "try:\n",
    "    line_count = 0\n",
    "    for line in process.stdout:\n",
    "        print(line, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        line_count += 1\n",
    "        \n",
    "        # 100è¡Œã”ã¨ã«çµŒéæ™‚é–“ã‚’è¡¨ç¤º\n",
    "        if line_count % 100 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"\\nâ±ï¸ çµŒéæ™‚é–“: {elapsed/60:.1f}åˆ†\")\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ å­¦ç¿’ã‚’ä¸­æ–­ã—ã¾ã—ãŸ\")\n",
    "    # ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†\n",
    "    process.terminate()\n",
    "    process.wait()\n",
    "    \n",
    "    # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèª\n",
    "    print(\"ğŸ’¾ é€”ä¸­ã¾ã§ã®å­¦ç¿’çµæœã‚’ç¢ºèªä¸­...\")\n",
    "    if os.path.exists(\"outputs\"):\n",
    "        import glob\n",
    "        ckpt_files = glob.glob('outputs/**/*.ckpt', recursive=True)\n",
    "        if ckpt_files:\n",
    "            print(f\"âœ… {len(ckpt_files)} å€‹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™\")\n",
    "        else:\n",
    "            print(\"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "process.wait()\n",
    "elapsed_total = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ… å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "print(f\"â±ï¸ ç·å­¦ç¿’æ™‚é–“: {elapsed_total/60:.1f}åˆ†\")\n",
    "print(\"ğŸ“‚ å‡ºåŠ›å…ˆ: outputs/\")\n",
    "\n",
    "# å­¦ç¿’çµæœã®ç°¡æ˜“ç¢ºèª\n",
    "if os.path.exists(\"outputs\"):\n",
    "    import glob\n",
    "    ckpt_files = glob.glob('outputs/**/*.ckpt', recursive=True)\n",
    "    config_files = glob.glob('outputs/**/config.yml', recursive=True)\n",
    "    print(f\"ğŸ“Š ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: .ckpt={len(ckpt_files)}å€‹, config.yml={len(config_files)}å€‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. å­¦ç¿’çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"=== å­¦ç¿’çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ===\")\n",
    "print(\"ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã™\")\n",
    "\n",
    "from google.colab import files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# outputs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª\n",
    "if not os.path.exists('outputs'):\n",
    "    print(\"âŒ outputs/ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"ğŸ’¡ å­¦ç¿’ãŒæ­£å¸¸ã«å®Œäº†ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "    exit()\n",
    "\n",
    "# outputs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ä½“æ§‹é€ ã‚’ç¢ºèª\n",
    "print(\"\\nğŸ“ å­¦ç¿’çµæœã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :\")\n",
    "!find outputs -type f | head -20\n",
    "\n",
    "# é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨çµ±è¨ˆ\n",
    "ckpt_files = glob.glob('outputs/**/*.ckpt', recursive=True)\n",
    "config_files = glob.glob('outputs/**/config.yml', recursive=True)\n",
    "json_files = glob.glob('outputs/**/*.json', recursive=True)\n",
    "\n",
    "print(f\"\\nğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ:\")\n",
    "print(f\"  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ(.ckpt): {len(ckpt_files)} å€‹\")\n",
    "print(f\"  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(.yml): {len(config_files)} å€‹\")\n",
    "print(f\"  JSONãƒ•ã‚¡ã‚¤ãƒ«(.json): {len(json_files)} å€‹\")\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®è¡¨ç¤º\n",
    "def get_file_size(filepath):\n",
    "    \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’MBå˜ä½ã§å–å¾—\"\"\"\n",
    "    try:\n",
    "        size_bytes = os.path.getsize(filepath)\n",
    "        return size_bytes / (1024 * 1024)  # MB\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "if ckpt_files:\n",
    "    print(f\"\\nğŸ“¥ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«(.ckpt)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    for file in ckpt_files:\n",
    "        if os.path.isfile(file):\n",
    "            size_mb = get_file_size(file)\n",
    "            print(f\"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file)} ({size_mb:.1f} MB)\")\n",
    "            try:\n",
    "                files.download(file)\n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "else:\n",
    "    print(\"\\nâŒ .ckptãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "    print(\"ğŸ’¡ å­¦ç¿’ãŒå®Œäº†ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "if config_files:\n",
    "    print(f\"\\nğŸ“¥ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(config.yml)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    for file in config_files:\n",
    "        if os.path.isfile(file):\n",
    "            size_mb = get_file_size(file)\n",
    "            print(f\"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file)} ({size_mb:.2f} MB)\")\n",
    "            try:\n",
    "                files.download(file)\n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "# JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ã‚ã‚Šï¼‰\n",
    "if json_files:\n",
    "    print(f\"\\nğŸ“¥ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    downloaded_count = 0\n",
    "    for file in json_files:\n",
    "        if downloaded_count >= 5:  # æœ€å¤§5å€‹ã¾ã§\n",
    "            break\n",
    "        if os.path.isfile(file):\n",
    "            size_mb = get_file_size(file)\n",
    "            if size_mb < 10:  # 10MBæœªæº€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿\n",
    "                print(f\"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file)} ({size_mb:.2f} MB)\")\n",
    "                try:\n",
    "                    files.download(file)\n",
    "                    downloaded_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            else:\n",
    "                print(f\"  ã‚¹ã‚­ãƒƒãƒ—: {os.path.basename(file)} (ã‚µã‚¤ã‚º: {size_mb:.1f} MB - å¤§ãã™ãã¾ã™)\")\n",
    "\n",
    "print(f\"\\nâœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼\")\n",
    "print(f\"ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ã§nerfstudio viewerã‚’ä½¿ã£ã¦çµæœã‚’ç¢ºèªã§ãã¾ã™\")\n",
    "print(f\"ğŸš€ ãƒ­ãƒ¼ã‚«ãƒ«ç¢ºèªã‚³ãƒãƒ³ãƒ‰: ns-viewer --load-config path/to/config.yml\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
