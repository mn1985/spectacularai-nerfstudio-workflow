{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726d1f9e",
   "metadata": {},
   "source": [
    "# oak-d Ã— spectacularAI Ã— nerfstudio Google Colab ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€oak-dã§æ’®å½±ã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆspectacularAIå½¢å¼ï¼‰ã‚’Google Colabã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€nerfstudioã§å­¦ç¿’ãƒ»å¯è¦–åŒ–ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¾ã§ã®ä¸€é€£ã®æ‰‹é †ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## æ¦‚è¦\n",
    "1. **Colabç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—** - PyTorch(GPUå¯¾å¿œ)ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨GPUç¢ºèª\n",
    "2. **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** - processed.zipã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»å±•é–‹\n",
    "3. **nerfstudioã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«** - nerfstudioã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨å‹•ä½œç¢ºèª\n",
    "4. **ãƒ‡ãƒ¼ã‚¿ç¢ºèª** - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ç¢ºèª\n",
    "5. **å­¦ç¿’å®Ÿè¡Œ** - nerfstudioã§ã®å­¦ç¿’ã¨GPUä½¿ç”¨çŠ¶æ³ç›£è¦–\n",
    "6. **çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰** - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«(.ckpt)ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "- ãƒ­ãƒ¼ã‚«ãƒ«ã§ `sai-cli process --format nerfstudio` ã«ã‚ˆã‚Š processed/ ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆæ¸ˆã¿\n",
    "- processed.zip ãƒ•ã‚¡ã‚¤ãƒ«ãŒæº–å‚™æ¸ˆã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779981cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Colabç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "print(\"=== Pythonãƒ»GPUç’°å¢ƒç¢ºèª ===\")\n",
    "!python --version\n",
    "!nvidia-smi  # GPUç¢ºèª\n",
    "\n",
    "print(\"\\n=== ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ===\")\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# GPUå¯¾å¿œPyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# nerfstudioã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install nerfstudio\n",
    "\n",
    "print(\"\\n=== GPUåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ ===\")\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(\"âœ… GPUå­¦ç¿’ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "else:\n",
    "    print(\"âŒ GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆCPUã§å­¦ç¿’ã•ã‚Œã¾ã™ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ãƒ‡ãƒ¼ã‚¿ã‚’Google Colabã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "# processed/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’zipãƒ•ã‚¡ã‚¤ãƒ«ã«ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\n",
    "# ãƒ­ãƒ¼ã‚«ãƒ«ã§: processed ãƒ•ã‚©ãƒ«ãƒ€ã‚’å³ã‚¯ãƒªãƒƒã‚¯ â†’ åœ§ç¸® â†’ processed.zip\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"processed.zip ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆNerfStudioå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ï¼‰\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"{filename} ã‚’å±•é–‹ã—ã¾ã—ãŸ\")\n",
    "        os.remove(filename)  # zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "\n",
    "# Windowsãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã®å•é¡Œã‚’ä¿®æ­£\n",
    "print(\"ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä¿®æ­£ä¸­...\")\n",
    "if os.path.exists('processed'):\n",
    "    # transforms.jsonã®ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä¿®æ­£\n",
    "    transforms_path = 'processed/transforms.json'\n",
    "    if os.path.exists(transforms_path):\n",
    "        import json\n",
    "        with open(transforms_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # ã™ã¹ã¦ã®ãƒ‘ã‚¹ã‚’ä¿®æ­£\n",
    "        if 'frames' in data:\n",
    "            for frame in data['frames']:\n",
    "                if 'file_path' in frame:\n",
    "                    # ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«å¤‰æ›\n",
    "                    frame['file_path'] = frame['file_path'].replace('\\\\', '/')\n",
    "        \n",
    "        # ä¿®æ­£ã—ãŸJSONã‚’ä¿å­˜\n",
    "        with open(transforms_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(\"âœ“ transforms.json ã®ãƒ‘ã‚¹ã‚’ä¿®æ­£ã—ã¾ã—ãŸ\")\n",
    "\n",
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ç¢ºèª\n",
    "print(\"\\n=== ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç¢ºèª ===\")\n",
    "!ls -la\n",
    "print(\"\\n=== processed/ å†…å®¹ç¢ºèª ===\")\n",
    "!ls -la processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86949505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. nerfstudioå‹•ä½œç¢ºèª\n",
    "print(\"=== nerfstudioå‹•ä½œç¢ºèª ===\")\n",
    "\n",
    "# nerfstudioã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ\n",
    "import nerfstudio\n",
    "print(\"âœ“ nerfstudio ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã—ãŸ\")\n",
    "\n",
    "# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª\n",
    "!pip show nerfstudio | grep Version\n",
    "\n",
    "# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ç¢ºèª\n",
    "print(\"\\n=== nerfstudioã‚³ãƒãƒ³ãƒ‰ç¢ºèª ===\")\n",
    "!ns-train --help | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
    "print(\"=== ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª ===\")\n",
    "!find processed -type f | head -20\n",
    "\n",
    "print(\"\\n=== å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª ===\")\n",
    "import os\n",
    "\n",
    "# transforms.jsonã®å­˜åœ¨ç¢ºèª\n",
    "if os.path.exists('processed/transforms.json'):\n",
    "    print(\"âœ“ transforms.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "else:\n",
    "    print(\"âŒ transforms.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª\n",
    "if os.path.exists('processed/images'):\n",
    "    image_count = len([f for f in os.listdir('processed/images') if f.endswith('.jpg')])\n",
    "    print(f\"âœ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã« {image_count} æšã®ç”»åƒãŒã‚ã‚Šã¾ã™\")\n",
    "    \n",
    "    if image_count > 0:\n",
    "        print(\"âœ… å­¦ç¿’æº–å‚™å®Œäº†ï¼\")\n",
    "    else:\n",
    "        print(\"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(\"âŒ images ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 5. Nerfstudioå­¦ç¿’ï¼‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°è¡¨ç¤º\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    print(\"=== å­¦ç¿’é–‹å§‹ ===\")\n",
    "    print(\"âš ï¸ å­¦ç¿’ã«ã¯æ•°åˆ†ã€œæ•°ååˆ†ã‹ã‹ã‚Šã¾ã™\\n\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ns-train\",\n",
    "        \"nerfacto\",\n",
    "        \"--pipeline.datamanager.data\", \"processed/\",\n",
    "        \"--output-dir\", \"outputs/\"\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for line in process.stdout:\n",
    "            print(line, end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸ å­¦ç¿’ã‚’ä¸­æ–­ã—ã¾ã—ãŸ\")\n",
    "        process.terminate()\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    print(\"\\nâœ… å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "    print(\"ãƒ­ã‚°ã¯ outputs/train.log ã«ã‚‚ä¿å­˜å¯èƒ½ã§ã™\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cdb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-2. å­¦ç¿’å®Œäº†ç›£è¦–\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def check_training_status():\n",
    "    print(\"=== å­¦ç¿’çŠ¶æ³ç¢ºèª ===\")\n",
    "    \n",
    "    # outputs/ãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèª\n",
    "    if os.path.exists('outputs/'):\n",
    "        print(\"âœ“ outputs/ ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸ\")\n",
    "        \n",
    "        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
    "        ckpt_files = glob.glob('outputs/**/*.ckpt', recursive=True)\n",
    "        if ckpt_files:\n",
    "            print(f\"âœ“ {len(ckpt_files)} å€‹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "            for file in ckpt_files[-2:]:  # æœ€æ–°2ã¤ã‚’è¡¨ç¤º\n",
    "                print(f\"  {file}\")\n",
    "            return True  # å­¦ç¿’å®Œäº†\n",
    "        else:\n",
    "            print(\"âš ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    else:\n",
    "        print(\"âš ï¸ outputs/ ãƒ•ã‚©ãƒ«ãƒ€ãŒã¾ã ä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "        print(\"å­¦ç¿’ãŒã¾ã é–‹å§‹ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "    \n",
    "    return False  # ã¾ã å­¦ç¿’ä¸­\n",
    "\n",
    "print(\"=== å­¦ç¿’å®Œäº†ã¾ã§è‡ªå‹•ç›£è¦–é–‹å§‹ ===\")\n",
    "print(\"å­¦ç¿’ãŒå®Œäº†ã™ã‚‹ã¾ã§30ç§’é–“éš”ã§ç¢ºèªã—ã¾ã™ï¼ˆæœ€å¤§30åˆ†é–“ï¼‰\")\n",
    "\n",
    "# å­¦ç¿’å®Œäº†ã¾ã§ç›£è¦–ï¼ˆ30ç§’é–“éš”ã§æœ€å¤§60å›=30åˆ†é–“ï¼‰\n",
    "max_checks = 60\n",
    "for i in range(max_checks):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"ğŸ“Š å­¦ç¿’ç›£è¦–ä¸­... ({i+1}/{max_checks}) - çµŒéæ™‚é–“: {i*0.5:.1f}åˆ†\")\n",
    "    \n",
    "    if check_training_status():\n",
    "        print(\"\\nğŸ‰ å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "        break\n",
    "    \n",
    "    if i < max_checks - 1:  # æœ€å¾Œã®ãƒã‚§ãƒƒã‚¯ã§ãªã„å ´åˆ\n",
    "        print(f\"\\nâ° æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§30ç§’å¾…æ©Ÿä¸­...\")\n",
    "        time.sleep(30)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ ç›£è¦–æ™‚é–“ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "# æœ€çµ‚çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ è¡¨ç¤º\n",
    "if os.path.exists('outputs/'):\n",
    "    print(\"\\n=== å­¦ç¿’çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ===\")\n",
    "    !find outputs -type f | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2751d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-1. å­¦ç¿’å¾Œã®GPUä½¿ç”¨çŠ¶æ³ç¢ºèª\n",
    "import torch\n",
    "\n",
    "print(\"=== å­¦ç¿’å¾Œã®GPUä½¿ç”¨çŠ¶æ³ç¢ºèª ===\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Current GPU memory used: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**3:.2f} GB\")\n",
    "    \n",
    "    # GPUä½¿ç”¨çŠ¶æ³è©³ç´°\n",
    "    print(\"\\n=== GPUè©³ç´°æƒ…å ± ===\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"âŒ CUDA ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. å­¦ç¿’çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"=== å­¦ç¿’çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ===\")\n",
    "print(\"ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã™\")\n",
    "\n",
    "from google.colab import files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# outputs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ä½“æ§‹é€ ã‚’ç¢ºèª\n",
    "print(\"\\nğŸ“ å­¦ç¿’çµæœã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :\")\n",
    "!find outputs -type f | head -20\n",
    "\n",
    "# é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨çµ±è¨ˆ\n",
    "ckpt_files = glob.glob('outputs/**/*.ckpt', recursive=True)\n",
    "config_files = glob.glob('outputs/**/config.yml', recursive=True)\n",
    "json_files = glob.glob('outputs/**/*.json', recursive=True)\n",
    "\n",
    "print(f\"\\nğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ:\")\n",
    "print(f\"  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ(.ckpt): {len(ckpt_files)} å€‹\")\n",
    "print(f\"  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(.yml): {len(config_files)} å€‹\")\n",
    "print(f\"  JSONãƒ•ã‚¡ã‚¤ãƒ«(.json): {len(json_files)} å€‹\")\n",
    "\n",
    "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "if ckpt_files:\n",
    "    print(f\"\\nğŸ“¥ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«(.ckpt)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    for file in ckpt_files:\n",
    "        if os.path.isfile(file):\n",
    "            print(f\"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file)}\")\n",
    "            files.download(file)\n",
    "else:\n",
    "    print(\"\\nâŒ .ckptãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "if config_files:\n",
    "    print(f\"\\nğŸ“¥ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(config.yml)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    for file in config_files:\n",
    "        if os.path.isfile(file):\n",
    "            print(f\"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file)}\")\n",
    "            files.download(file)\n",
    "\n",
    "# JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "if json_files:\n",
    "    print(f\"\\nğŸ“¥ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    for file in json_files[:5]:  # æœ€å¤§5å€‹ã¾ã§\n",
    "        if os.path.isfile(file):\n",
    "            print(f\"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file)}\")\n",
    "            files.download(file)\n",
    "\n",
    "print(f\"\\nâœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼\")\n",
    "print(f\"ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ã§nerfstudio viewerã‚’ä½¿ã£ã¦çµæœã‚’ç¢ºèªã§ãã¾ã™\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
