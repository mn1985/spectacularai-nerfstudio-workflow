{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "726d1f9e",
      "metadata": {
        "id": "726d1f9e"
      },
      "source": [
        "# oak-d × spectacularAI × nerfstudio Google Colab ワークフロー\n",
        "\n",
        "このノートブックは、oak-dで撮影したデータ（spectacularAI形式）をGoogle Colabにアップロードし、nerfstudioで学習・可視化・ダウンロードするまでの一連の手順をまとめたものです。\n",
        "\n",
        "---\n",
        "\n",
        "## 概要\n",
        "1. **Colab環境セットアップ** - PyTorch(GPU対応)のインストールとGPU詳細確認\n",
        "2. **データアップロード** - processed.zipをアップロード・展開・パス修正\n",
        "3. **nerfstudioインストール** - nerfstudioのインストールと動作確認\n",
        "4. **データ確認** - アップロードしたデータの詳細構造確認\n",
        "5. **学習実行** - nerfstudioでの学習とGPU使用状況監視・進捗表示\n",
        "6. **学習結果確認** - 学習済みモデル(.ckpt)とconfig.ymlの生成確認\n",
        "7. **複数形式エクスポート** - 点群・カメラ・Gaussian Splatなど複数形式でエクスポート\n",
        "8. **代替エクスポート** - エクスポートコマンドが失敗した場合の直接ファイルアクセス\n",
        "9. **品質確認＆可視化** - 学習メトリクス・レンダリング結果・リソース使用状況の確認\n",
        "10. **ダウンロード＆アーカイブ** - 各種3Dデータ形式のColab環境からのダウンロード\n",
        "\n",
        "## 前提条件\n",
        "- ローカルで `sai-cli process --format nerfstudio` により processed/ フォルダが作成済み\n",
        "- processed.zip ファイルが準備済み\n",
        "\n",
        "## 主な改善点\n",
        "- **Windows互換性**: パス区切り文字の自動修正機能\n",
        "- **GPU監視**: リアルタイムGPUメモリ使用量表示\n",
        "- **エラーハンドリング**: 各段階での詳細なエラー診断\n",
        "- **ファイル管理**: サイズ確認付きの選択的ダウンロード\n",
        "- **進捗表示**: 経過時間とステップ数の監視\n",
        "- **複数エクスポート**: pointcloud・cameras・gaussian-splatなど複数形式対応\n",
        "- **ビューワ統合**: Colab内インタラクティブ3Dビューワ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzGaXPcPJGOX",
        "outputId": "fd0286ab-794c-4c25-ea4e-0907f1db4411"
      },
      "id": "KzGaXPcPJGOX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "779981cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "779981cb",
        "outputId": "9f613c9e-327e-46db-e5d8-9b4a1b740d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Google Colab環境確認 ===\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "name, memory.total [MiB], memory.free [MiB]\n",
            "Tesla T4, 15360 MiB, 15095 MiB\n",
            "\n",
            "=== Google Colab固有設定 ===\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "\n",
            "=== GPU対応PyTorchインストール ===\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\n",
            "CUDA available: True\n",
            "GPU device: Tesla T4\n",
            "GPU memory: 14.7 GB\n",
            "CUDA version: 12.6\n",
            "GPU学習環境が正常に設定されました\n"
          ]
        }
      ],
      "source": [
        "# 1. Google Colab環境セットアップ\n",
        "import sys\n",
        "print(\"=== Google Colab環境確認 ===\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# GPU確認\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
        "\n",
        "print(\"\\n=== Google Colab固有設定 ===\")\n",
        "# Google Driveマウント（オプション）\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# パッケージの最新化\n",
        "!pip install --upgrade pip\n",
        "\n",
        "print(\"\\n=== GPU対応PyTorchインストール ===\")\n",
        "# Colab推奨のPyTorchインストール\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# GPU利用可能性の詳細チェック\n",
        "import torch\n",
        "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(\"GPU学習環境が正常に設定されました\")\n",
        "else:\n",
        "    print(\"GPU が利用できません\")\n",
        "    print(\"ランタイム → ランタイムのタイプを変更してください\")\n",
        "    print(\"注意: GPU なしでも学習は可能ですが、非常に時間がかかります\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5fb7e655",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "5fb7e655",
        "outputId": "2df67a9d-7241-45ad-d776-d24e1ea27824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Google Colab データアップロード ===\n",
            "processed.zip ファイルをアップロードしてください\n",
            "ファイルサイズが大きい場合は、Google Driveからの読み込みも可能です\n",
            "\n",
            "[方法1] 直接アップロード:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0256848d-3b0c-458d-8eb8-d9b1efee40f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0256848d-3b0c-458d-8eb8-d9b1efee40f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed.zip to processed.zip\n",
            "アップロード完了\n",
            "\n",
            "processed.zip を展開中...\n",
            "processed.zip を展開しました\n",
            "zipファイルを削除しました（容量節約のため）\n",
            "\n",
            "=== Colab環境用パス修正 ===\n",
            "transforms.json のパスをColab環境用に修正しました\n",
            "\n",
            "=== アップロード結果確認 ===\n",
            "total 3309\n",
            "drwx------ 3 root root    4096 Aug 29 14:10 colmap\n",
            "drwx------ 2 root root    4096 Aug 29 14:10 images\n",
            "-rw------- 1 root root 3337406 Aug 29 14:10 sparse_pc.ply\n",
            "-rw------- 1 root root   41824 Aug 29 14:10 transforms.json\n",
            "画像ファイル数: 86\n",
            "\n",
            "Colab環境でのデータ準備が完了しました\n"
          ]
        }
      ],
      "source": [
        "# 2. データアップロードとGoogle Colab最適化\n",
        "print(\"=== Google Colab データアップロード ===\")\n",
        "print(\"processed.zip ファイルをアップロードしてください\")\n",
        "print(\"ファイルサイズが大きい場合は、Google Driveからの読み込みも可能です\")\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ファイルアップロード\n",
        "print(\"\\n[方法1] 直接アップロード:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"\\nファイルがアップロードされませんでした\")\n",
        "    print(\"\\n[方法2] Google Driveを使用する場合:\")\n",
        "    print(\"以下のコードのコメントアウトを解除してください:\")\n",
        "    print(\"# from google.colab import drive\")\n",
        "    print(\"# drive.mount('/content/drive')\")\n",
        "    print(\"# import shutil\")\n",
        "    print(\"# shutil.copy('/content/drive/MyDrive/processed.zip', '/content/')\")\n",
        "else:\n",
        "    print(\"アップロード完了\")\n",
        "\n",
        "# zipファイル展開処理\n",
        "for filename in uploaded.keys() if uploaded else []:\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"\\n{filename} を展開中...\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content/drive/MyDrive/')\n",
        "            print(f\"{filename} を展開しました\")\n",
        "            os.remove(filename)  # zipファイルを削除してディスク容量節約\n",
        "            print(\"zipファイルを削除しました（容量節約のため）\")\n",
        "        except Exception as e:\n",
        "            print(f\"展開エラー: {e}\")\n",
        "            continue\n",
        "\n",
        "# Google Colab環境でのパス正規化\n",
        "print(\"\\n=== Colab環境用パス修正 ===\")\n",
        "processed_path = '/content/drive/MyDrive/processed'\n",
        "if os.path.exists(processed_path):\n",
        "    # transforms.jsonのパス区切り文字を修正\n",
        "    transforms_path = os.path.join(processed_path, 'transforms.json')\n",
        "    if os.path.exists(transforms_path):\n",
        "        try:\n",
        "            with open(transforms_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            path_fixed = False\n",
        "            # Colab環境用にパスを正規化\n",
        "            if 'frames' in data:\n",
        "                for frame in data['frames']:\n",
        "                    if 'file_path' in frame:\n",
        "                        original_path = frame['file_path']\n",
        "                        # バックスラッシュをスラッシュに変換\n",
        "                        normalized_path = original_path.replace('\\\\', '/')\n",
        "                        # 先頭が './' でない場合は追加\n",
        "                        if not normalized_path.startswith('./'):\n",
        "                            normalized_path = './' + normalized_path.lstrip('./')\n",
        "\n",
        "                        if original_path != normalized_path:\n",
        "                            frame['file_path'] = normalized_path\n",
        "                            path_fixed = True\n",
        "\n",
        "            if path_fixed:\n",
        "                with open(transforms_path, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(data, f, indent=2)\n",
        "                print(\"transforms.json のパスをColab環境用に修正しました\")\n",
        "            else:\n",
        "                print(\"transforms.json のパスは既に正規化されています\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"パス修正エラー: {e}\")\n",
        "    else:\n",
        "        print(\"transforms.json が見つかりません\")\n",
        "\n",
        "    # ディレクトリ構造確認\n",
        "    print(\"\\n=== アップロード結果確認 ===\")\n",
        "    !ls -la /content/drive/MyDrive/processed/\n",
        "\n",
        "    # 画像フォルダ確認\n",
        "    images_path = os.path.join(processed_path, 'images')\n",
        "    if os.path.exists(images_path):\n",
        "        image_count = len([f for f in os.listdir(images_path)\n",
        "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"画像ファイル数: {image_count}\")\n",
        "\n",
        "else:\n",
        "    print(\"processed/ フォルダが見つかりません\")\n",
        "    print(\"zipファイルの内容を確認してください\")\n",
        "\n",
        "print(\"\\nColab環境でのデータ準備が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86949505",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "86949505",
        "outputId": "1357de53-8459-41d3-9837-f43e71645765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== nerfstudio Colab専用インストール ===\n",
            "nerfstudio をColab環境用にインストール中...\n",
            "これには数分かかる場合があります...\n",
            "Collecting nerfstudio\n",
            "  Downloading nerfstudio-1.1.5-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting appdirs>=1.4 (from nerfstudio)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting av>=9.2.0 (from nerfstudio)\n",
            "  Downloading av-15.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting comet-ml>=3.33.8 (from nerfstudio)\n",
            "  Downloading comet_ml-3.52.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: cryptography>=38 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (43.0.3)\n",
            "Collecting tyro>=0.6.6 (from nerfstudio)\n",
            "  Downloading tyro-0.9.29-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gdown>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (5.2.0)\n",
            "Collecting ninja>=1.10 (from nerfstudio)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (3.14.0)\n",
            "Requirement already satisfied: imageio>=2.21.1 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (2.37.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (7.7.1)\n",
            "Collecting jaxtyping>=0.2.15 (from nerfstudio)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting jupyterlab>=3.3.4 (from nerfstudio)\n",
            "  Downloading jupyterlab-4.4.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (3.10.0)\n",
            "Collecting mediapy>=1.1.0 (from nerfstudio)\n",
            "  Downloading mediapy-1.2.4-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: msgpack>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (1.1.1)\n",
            "Collecting msgpack-numpy>=0.4.8 (from nerfstudio)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting nerfacc==0.5.2 (from nerfstudio)\n",
            "  Downloading nerfacc-0.5.2-py3-none-any.whl.metadata (877 bytes)\n",
            "Collecting open3d>=0.16.0 (from nerfstudio)\n",
            "  Downloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from nerfstudio)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (11.3.0)\n",
            "Requirement already satisfied: plotly>=5.7.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (5.24.1)\n",
            "Collecting protobuf!=3.20.0,<=3.20.3 (from nerfstudio)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting pyngrok>=5.1.0 (from nerfstudio)\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting python-socketio>=5.7.1 (from nerfstudio)\n",
            "  Downloading python_socketio-5.13.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pyquaternion>=0.9.9 (from nerfstudio)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (2.32.4)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (13.9.4)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (0.25.2)\n",
            "Collecting splines==0.3.0 (from nerfstudio)\n",
            "  Downloading splines-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (2.19.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (0.23.0+cu126)\n",
            "Collecting torchmetrics>=1.0.1 (from torchmetrics[image]>=1.0.1->nerfstudio)\n",
            "  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (4.15.0)\n",
            "Collecting viser==0.2.7 (from nerfstudio)\n",
            "  Downloading viser-0.2.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting nuscenes-devkit>=1.1.1 (from nerfstudio)\n",
            "  Downloading nuscenes_devkit-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: wandb>=0.13.3 in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (0.21.1)\n",
            "Collecting xatlas (from nerfstudio)\n",
            "  Downloading xatlas-0.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting trimesh>=3.20.2 (from nerfstudio)\n",
            "  Downloading trimesh-4.7.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting timm==0.6.7 (from nerfstudio)\n",
            "  Downloading timm-0.6.7-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting gsplat==1.4.0 (from nerfstudio)\n",
            "  Downloading gsplat-1.4.0-py3-none-any.whl.metadata (957 bytes)\n",
            "Collecting pytorch-msssim (from nerfstudio)\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting pathos (from nerfstudio)\n",
            "  Downloading pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nerfstudio) (25.0)\n",
            "Collecting fpsample (from nerfstudio)\n",
            "  Downloading fpsample-0.3.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting tensorly (from nerfstudio)\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting rawpy>=0.18.1 (from nerfstudio)\n",
            "  Downloading rawpy-0.25.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting pymeshlab>=2022.2.post2 (from nerfstudio)\n",
            "  Downloading pymeshlab-2023.12.post3-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from gsplat==1.4.0->nerfstudio) (2.0.2)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.7->nerfstudio) (15.0.1)\n",
            "Collecting msgspec>=0.18.6 (from viser==0.2.7->nerfstudio)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.7->nerfstudio) (1.16.1)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.7->nerfstudio) (4.67.1)\n",
            "Collecting nodeenv>=1.8.0 (from viser==0.2.7->nerfstudio)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: psutil>=5.9.5 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.7->nerfstudio) (5.9.5)\n",
            "Collecting yourdfpy>=0.0.53 (from viser==0.2.7->nerfstudio)\n",
            "  Downloading yourdfpy-0.0.58-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting plyfile>=1.0.2 (from viser==0.2.7->nerfstudio)\n",
            "  Downloading plyfile-1.1.2-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting pyliblzfse>=0.4.1 (from viser==0.2.7->nerfstudio)\n",
            "  Downloading pyliblzfse-0.4.1.tar.gz (47 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet-ml>=3.33.8->nerfstudio)\n",
            "  Downloading dulwich-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet-ml>=3.33.8->nerfstudio)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (4.25.1)\n",
            "Collecting python-box<7.0.0 (from comet-ml>=3.33.8->nerfstudio)\n",
            "  Downloading python_box-6.1.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (1.0.0)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (2.35.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (75.2.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (3.20.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (1.17.3)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from comet-ml>=3.33.8->nerfstudio) (3.1.1)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet-ml>=3.33.8->nerfstudio)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=38->nerfstudio) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=38->nerfstudio) (2.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.6.0->nerfstudio) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.6.0->nerfstudio) (3.19.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6->nerfstudio) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6->nerfstudio) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6->nerfstudio) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6->nerfstudio) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6->nerfstudio) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6->nerfstudio) (3.0.15)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6->nerfstudio) (6.5.7)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (0.2.13)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.15->nerfstudio)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.33.8->nerfstudio) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.33.8->nerfstudio) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.33.8->nerfstudio) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.33.8->nerfstudio) (0.27.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (4.3.8)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=3.3.4->nerfstudio) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=3.3.4->nerfstudio) (3.1.6)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=3.3.4->nerfstudio) (0.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=3.3.4->nerfstudio) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=3.3.4->nerfstudio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=3.3.4->nerfstudio) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=3.3.4->nerfstudio) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=3.3.4->nerfstudio) (0.16.0)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (25.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (0.22.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3.3.4->nerfstudio) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab>=3.3.4->nerfstudio) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (25.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyterlab>=3.3.4->nerfstudio) (3.0.2)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (3.0.0)\n",
            "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (24.11.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->nerfstudio) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->nerfstudio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->nerfstudio) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->nerfstudio) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->nerfstudio) (3.2.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (1.5.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio) (2.21.2)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6->nerfstudio) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (0.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from nuscenes-devkit>=1.1.1->nerfstudio) (5.5.2)\n",
            "Collecting descartes (from nuscenes-devkit>=1.1.1->nerfstudio)\n",
            "  Downloading descartes-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting fire (from nuscenes-devkit>=1.1.1->nerfstudio)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting numpy (from gsplat==1.4.0->nerfstudio)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from nuscenes-devkit>=1.1.1->nerfstudio) (1.6.1)\n",
            "Collecting Shapely~=2.0.3 (from nuscenes-devkit>=1.1.1->nerfstudio)\n",
            "  Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting parameterized (from nuscenes-devkit>=1.1.1->nerfstudio)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from nuscenes-devkit>=1.1.1->nerfstudio) (2.0.10)\n",
            "Collecting dash>=2.6.0 (from open3d>=0.16.0->nerfstudio)\n",
            "  Downloading dash-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d>=0.16.0->nerfstudio) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d>=0.16.0->nerfstudio) (3.1.2)\n",
            "Collecting configargparse (from open3d>=0.16.0->nerfstudio)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=7.6 (from nerfstudio)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d>=0.16.0->nerfstudio)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from open3d>=0.16.0->nerfstudio) (2.2.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d>=0.16.0->nerfstudio) (8.7.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d>=0.16.0->nerfstudio)\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d>=0.16.0->nerfstudio) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d>=0.16.0->nerfstudio) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d>=0.16.0->nerfstudio) (2.2.0)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=7.6->nerfstudio)\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=7.6->nerfstudio)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d>=0.16.0->nerfstudio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d>=0.16.0->nerfstudio) (2025.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.6->nerfstudio) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.7.0->nerfstudio) (8.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6->nerfstudio) (1.17.0)\n",
            "Collecting bidict>=0.21.0 (from python-socketio>=5.7.1->nerfstudio)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting python-engineio>=4.11.0 (from python-socketio>=5.7.1->nerfstudio)\n",
            "  Downloading python_engineio-4.12.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio>=5.7.1->nerfstudio)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->nerfstudio) (3.4.3)\n",
            "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.5.1->nerfstudio) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->nerfstudio) (0.1.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nerfstudio) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nerfstudio) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nerfstudio) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nuscenes-devkit>=1.1.1->nerfstudio) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nuscenes-devkit>=1.1.1->nerfstudio) (3.6.0)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.7.1->nerfstudio)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->nerfstudio) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->nerfstudio) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->nerfstudio) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->nerfstudio) (0.7.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (1.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->nerfstudio) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.1->nerfstudio) (1.3.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics>=1.0.1->torchmetrics[image]>=1.0.1->nerfstudio)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]>=1.0.1->nerfstudio)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.6.6->nerfstudio) (0.17.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.6.6->nerfstudio)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.6.6->nerfstudio) (4.4.4)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.3->nerfstudio) (3.1.45)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.3->nerfstudio) (2.11.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.3->nerfstudio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.3->nerfstudio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.3->nerfstudio) (0.4.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.3->nerfstudio) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.3->nerfstudio) (5.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from yourdfpy>=0.0.53->viser==0.2.7->nerfstudio) (5.4.0)\n",
            "Collecting colorlog (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting manifold3d>=2.3.0 (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading manifold3d-3.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n",
            "Collecting svg.path (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading svg_path-7.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pycollada (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio) (3.5.0)\n",
            "Collecting rtree (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting embreex (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading embreex-2.17.7.post6-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting vhacdx (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading vhacdx-0.0.8.post2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting mapbox_earcut>=1.0.2 (from trimesh[easy]>=3.11.2->yourdfpy>=0.0.53->viser==0.2.7->nerfstudio)\n",
            "  Downloading mapbox_earcut-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.6.0->nerfstudio) (2.7)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->nuscenes-devkit>=1.1.1->nerfstudio) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->dash>=2.6.0->open3d>=0.16.0->nerfstudio) (3.23.0)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.3.4->nerfstudio)\n",
            "  Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ppft>=1.7.7 (from pathos->nerfstudio)\n",
            "  Downloading ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.4.0 (from pathos->nerfstudio)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.6 (from pathos->nerfstudio)\n",
            "  Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.18 (from pathos->nerfstudio)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.6.0->nerfstudio) (1.7.1)\n",
            "Downloading nerfstudio-1.1.5-py3-none-any.whl (580 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.8/580.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gsplat-1.4.0-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nerfacc-0.5.2-py3-none-any.whl (55 kB)\n",
            "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading splines-0.3.0-py3-none-any.whl (17 kB)\n",
            "Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "Downloading viser-0.2.7-py3-none-any.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading av-15.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comet_ml-3.52.0-py3-none-any.whl (743 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m743.7/743.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Downloading python_box-6.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading dulwich-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.6-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m185.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
            "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading mediapy-1.2.4-py3-none-any.whl (26 kB)\n",
            "Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "Downloading nuscenes_devkit-1.2.0-py3-none-any.whl (315 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m192.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m\n",
            "\u001b[?25hDownloading dash-3.2.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading plyfile-1.1.2-py3-none-any.whl (36 kB)\n",
            "Downloading pymeshlab-2023.12.post3-cp312-cp312-manylinux_2_31_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading python_socketio-5.13.0-py3-none-any.whl (77 kB)\n",
            "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading python_engineio-4.12.2-py3-none-any.whl (59 kB)\n",
            "Downloading rawpy-0.25.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "Downloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading trimesh-4.7.4-py3-none-any.whl (709 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.29-py3-none-any.whl (129 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Downloading yourdfpy-0.0.58-py3-none-any.whl (22 kB)\n",
            "Downloading manifold3d-3.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapbox_earcut-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading embreex-2.17.7.post6-cp312-cp312-manylinux_2_28_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m155.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Downloading fpsample-0.3.3-cp312-cp312-manylinux_2_28_x86_64.whl (331 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pathos-0.3.4-py3-none-any.whl (82 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "Downloading pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "Downloading pycollada-0.9.2-py3-none-any.whl (128 kB)\n",
            "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "Downloading svg_path-7.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading vhacdx-0.0.8.post2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (265 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading xatlas-0.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (260 kB)\n",
            "Building wheels for collected packages: pyliblzfse\n",
            "\u001b[33m  DEPRECATION: Building 'pyliblzfse' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyliblzfse'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for pyliblzfse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyliblzfse: filename=pyliblzfse-0.4.1-cp312-cp312-linux_x86_64.whl size=88094 sha256=9084b507db5d609ae10fb4b7d265b8751460283e99f96a76cb16d95234328332\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/bf/ee/8b734d20d3cc3e31b20be7c2aab7c407c9826dd03d87e1acf6\n",
            "Successfully built pyliblzfse\n",
            "Installing collected packages: pyliblzfse, everett, appdirs, addict, xatlas, wsproto, widgetsnbextension, wadler-lindig, uri-template, types-python-dateutil, svg.path, shtab, rtree, rfc3986-validator, rfc3339-validator, retrying, python-json-logger, python-box, pyngrok, protobuf, ppft, pox, parameterized, numpy, nodeenv, ninja, msgspec, lightning-utilities, lark, json5, jedi, fqdn, fire, dulwich, dill, configobj, configargparse, comm, colorlog, bidict, av, async-lru, vhacdx, trimesh, splines, simple-websocket, Shapely, rfc3987-syntax, rawpy, pyquaternion, pymeshlab, pycollada, plyfile, opencv-python-headless, multiprocess, msgpack-numpy, mapbox_earcut, manifold3d, jupyter-server-terminals, jupyter-client, jaxtyping, fpsample, embreex, arrow, tyro, tensorly, python-engineio, pathos, isoduration, ipywidgets, dash, torchmetrics, pytorch-msssim, python-socketio, nerfacc, mediapy, gsplat, descartes, comet-ml, yourdfpy, torch-fidelity, timm, open3d, nuscenes-devkit, jupyter-events, viser, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, nerfstudio\n",
            "\u001b[2K  Attempting uninstall: widgetsnbextension\n",
            "\u001b[2K    Found existing installation: widgetsnbextension 3.6.10\n",
            "\u001b[2K    Uninstalling widgetsnbextension-3.6.10:\n",
            "\u001b[2K      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "\u001b[2K  Attempting uninstall: python-box\n",
            "\u001b[2K    Found existing installation: python-box 7.3.2\n",
            "\u001b[2K    Uninstalling python-box-7.3.2:\n",
            "\u001b[2K      Successfully uninstalled python-box-7.3.2\n",
            "\u001b[2K  Attempting uninstall: protobuf\n",
            "\u001b[2K    Found existing installation: protobuf 5.29.5\n",
            "\u001b[2K    Uninstalling protobuf-5.29.5:\n",
            "\u001b[2K      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: dill\n",
            "\u001b[2K    Found existing installation: dill 0.3.8\n",
            "\u001b[2K    Uninstalling dill-0.3.8:\n",
            "\u001b[2K      Successfully uninstalled dill-0.3.8\n",
            "\u001b[2K  Attempting uninstall: Shapely\n",
            "\u001b[2K    Found existing installation: shapely 2.1.1\n",
            "\u001b[2K    Uninstalling shapely-2.1.1:\n",
            "\u001b[2K      Successfully uninstalled shapely-2.1.1\n",
            "\u001b[2K  Attempting uninstall: opencv-python-headless\n",
            "\u001b[2K    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "\u001b[2K    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "\u001b[2K      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "\u001b[2K  Attempting uninstall: multiprocess\n",
            "\u001b[2K    Found existing installation: multiprocess 0.70.16\n",
            "\u001b[2K    Uninstalling multiprocess-0.70.16:\n",
            "\u001b[2K      Successfully uninstalled multiprocess-0.70.16\n",
            "\u001b[2K  Attempting uninstall: jupyter-client\n",
            "\u001b[2K    Found existing installation: jupyter-client 6.1.12\n",
            "\u001b[2K    Uninstalling jupyter-client-6.1.12:\n",
            "\u001b[2K      Successfully uninstalled jupyter-client-6.1.12\n",
            "\u001b[2K  Attempting uninstall: ipywidgets\n",
            "\u001b[2K    Found existing installation: ipywidgets 7.7.1\n",
            "\u001b[2K    Uninstalling ipywidgets-7.7.1:\n",
            "\u001b[2K      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[2K  Attempting uninstall: timm\n",
            "\u001b[2K    Found existing installation: timm 1.0.19\n",
            "\u001b[2K    Uninstalling timm-1.0.19:\n",
            "\u001b[2K      Successfully uninstalled timm-1.0.19\n",
            "\u001b[2K  Attempting uninstall: jupyter-server\n",
            "\u001b[2K    Found existing installation: jupyter-server 1.16.0\n",
            "\u001b[2K    Uninstalling jupyter-server-1.16.0:\n",
            "\u001b[2K      Successfully uninstalled jupyter-server-1.16.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91/91\u001b[0m [nerfstudio]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires jupyter-server==1.16.0, but you have jupyter-server 2.17.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "datasets 4.0.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
            "datasets 4.0.0 requires multiprocess<0.70.17, but you have multiprocess 0.70.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Shapely-2.0.7 addict-2.4.0 appdirs-1.4.4 arrow-1.3.0 async-lru-2.0.5 av-15.0.0 bidict-0.23.1 colorlog-6.9.0 comet-ml-3.52.0 comm-0.2.3 configargparse-1.7.1 configobj-5.0.9 dash-3.2.0 descartes-1.1.0 dill-0.4.0 dulwich-0.24.1 embreex-2.17.7.post6 everett-3.1.0 fire-0.7.1 fpsample-0.3.3 fqdn-1.5.1 gsplat-1.4.0 ipywidgets-8.1.7 isoduration-20.11.0 jaxtyping-0.3.2 jedi-0.19.2 json5-0.12.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.6 jupyterlab-server-2.27.3 lark-1.2.2 lightning-utilities-0.15.2 manifold3d-3.2.1 mapbox_earcut-1.0.3 mediapy-1.2.4 msgpack-numpy-0.4.8 msgspec-0.19.0 multiprocess-0.70.18 nerfacc-0.5.2 nerfstudio-1.1.5 ninja-1.13.0 nodeenv-1.9.1 numpy-1.26.4 nuscenes-devkit-1.2.0 open3d-0.19.0 opencv-python-headless-4.10.0.84 parameterized-0.9.0 pathos-0.3.4 plyfile-1.1.2 pox-0.3.6 ppft-1.7.7 protobuf-3.20.3 pycollada-0.9.2 pyliblzfse-0.4.1 pymeshlab-2023.12.post3 pyngrok-7.3.0 pyquaternion-0.9.9 python-box-6.1.0 python-engineio-4.12.2 python-json-logger-3.3.0 python-socketio-5.13.0 pytorch-msssim-1.0.0 rawpy-0.25.1 retrying-1.4.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rtree-1.4.1 shtab-1.7.2 simple-websocket-1.1.0 splines-0.3.0 svg.path-7.0 tensorly-0.9.0 timm-0.6.7 torch-fidelity-0.3.0 torchmetrics-1.8.1 trimesh-4.7.4 types-python-dateutil-2.9.0.20250822 tyro-0.9.29 uri-template-1.3.0 vhacdx-0.0.8.post2 viser-0.2.7 wadler-lindig-0.1.7 widgetsnbextension-4.0.14 wsproto-1.2.0 xatlas-0.0.11 yourdfpy-0.0.58\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dill",
                  "google",
                  "numpy"
                ]
              },
              "id": "67cd4e5a12714ef99ac8287a8fcd0d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== インストール確認 ===\n",
            "nerfstudio が正常にインポートできました\n",
            "Version: 1.1.5\n",
            "\n",
            "=== Colab環境でのnerfstudioコマンド確認 ===\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/ns-train\", line 3, in <module>\n",
            "    from nerfstudio.scripts.train import entrypoint\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nerfstudio/scripts/train.py\", line 62, in <module>\n",
            "    from nerfstudio.configs.method_configs import AnnotatedBaseConfigUnion\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nerfstudio/configs/method_configs.py\", line 26, in <module>\n",
            "    from nerfstudio.cameras.camera_optimizers import CameraOptimizerConfig\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/camera_optimizers.py\", line 35, in <module>\n",
            "    from nerfstudio.configs.base_config import InstantiateConfig\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nerfstudio/configs/base_config.py\", line 24, in <module>\n",
            "    from nerfstudio.utils import writer\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nerfstudio/utils/writer.py\", line 31, in <module>\n",
            "    from torch.utils.tensorboard import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/tensorboard/writer.py\", line 16, in <module>\n",
            "    from tensorboard.summary.writer.event_file_writer import EventFileWriter\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/summary/__init__.py\", line 33, in <module>\n",
            "    from tensorboard.summary._output import DirectoryOutput  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/summary/_output.py\", line 19, in <module>\n",
            "    from tensorboard.summary.writer import event_file_writer\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 215, in <module>\n",
            "    class _AsyncWriterThread(threading.Thread):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\n",
            "=== 利用可能なメソッド確認 ===\n",
            "^C\n",
            "\n",
            "nerfstudio のColab環境セットアップが完了しました\n",
            "\n",
            "=== Colab環境用最適化設定 ===\n",
            "Colab環境用の最適化設定が完了しました\n"
          ]
        }
      ],
      "source": [
        "# 3. nerfstudio Google Colab専用インストール\n",
        "print(\"=== nerfstudio Colab専用インストール ===\")\n",
        "\n",
        "# Colab環境でのnerfstudioインストール\n",
        "print(\"nerfstudio をColab環境用にインストール中...\")\n",
        "print(\"これには数分かかる場合があります...\")\n",
        "\n",
        "# 依存関係とnerfstudioのインストール\n",
        "!pip install nerfstudio\n",
        "\n",
        "# インストール確認とバージョン表示\n",
        "print(\"\\n=== インストール確認 ===\")\n",
        "try:\n",
        "    import nerfstudio\n",
        "    print(\"nerfstudio が正常にインポートできました\")\n",
        "\n",
        "    # バージョン情報\n",
        "    !pip show nerfstudio | grep Version\n",
        "\n",
        "    # Colab環境での基本コマンド確認\n",
        "    print(\"\\n=== Colab環境でのnerfstudioコマンド確認 ===\")\n",
        "    !ns-train --help | head -10\n",
        "\n",
        "    print(\"\\n=== 利用可能なメソッド確認 ===\")\n",
        "    !ns-train -h | grep -A5 \"method\"\n",
        "\n",
        "    print(\"\\nnerfstudio のColab環境セットアップが完了しました\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"nerfstudio インポートエラー: {e}\")\n",
        "    print(\"ランタイムを再起動してから再実行してください\")\n",
        "except Exception as e:\n",
        "    print(f\"セットアップエラー: {e}\")\n",
        "\n",
        "# Colab環境用の追加設定\n",
        "print(\"\\n=== Colab環境用最適化設定 ===\")\n",
        "import os\n",
        "# 環境変数設定（Colab用）\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # GPU使用指定\n",
        "os.environ['PYTHONPATH'] = '/content'      # Python パス設定\n",
        "\n",
        "print(\"Colab環境用の最適化設定が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4511df05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4511df05",
        "outputId": "b38deea9-c80b-4fff-bfdc-909291726f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Google Colab データ検証 ===\n",
            "データ構造確認:\n",
            "/content/drive/MyDrive/processed/colmap/sparse/0/cameras.txt\n",
            "/content/drive/MyDrive/processed/colmap/sparse/0/images.txt\n",
            "/content/drive/MyDrive/processed/colmap/sparse/0/points3D.txt\n",
            "/content/drive/MyDrive/processed/images/depth_00001.png\n",
            "/content/drive/MyDrive/processed/images/depth_00002.png\n",
            "/content/drive/MyDrive/processed/images/depth_00003.png\n",
            "/content/drive/MyDrive/processed/images/depth_00004.png\n",
            "/content/drive/MyDrive/processed/images/depth_00005.png\n",
            "/content/drive/MyDrive/processed/images/depth_00006.png\n",
            "/content/drive/MyDrive/processed/images/depth_00007.png\n",
            "/content/drive/MyDrive/processed/images/depth_00008.png\n",
            "/content/drive/MyDrive/processed/images/depth_00009.png\n",
            "/content/drive/MyDrive/processed/images/depth_00010.png\n",
            "/content/drive/MyDrive/processed/images/depth_00011.png\n",
            "/content/drive/MyDrive/processed/images/depth_00012.png\n",
            "\n",
            "=== transforms.json 検証 ===\n",
            "transforms.json が見つかりました\n",
            "カメラ内部パラメータ確認:\n",
            "  focal length x: 426.952\n",
            "  総フレーム数: 43\n",
            "  サンプルパス: ./images/frame_00001.jpg\n",
            "  パス形式: 正規化済み (Colab対応)\n",
            "  ファイル存在確認: OK\n",
            "transforms.json の検証が完了しました\n",
            "\n",
            "=== 画像データ検証 ===\n",
            "画像ファイル統計:\n",
            "  JPG/JPEG: 43 枚\n",
            "  PNG: 43 枚\n",
            "  合計: 86 枚\n",
            "  サンプル画像: frame_00001.jpg (67.0 KB)\n",
            "Colab学習に適した画像数です\n",
            "\n",
            "Colab環境でのデータ検証完了\n",
            "学習準備が整いました！\n",
            "\n",
            "=== オプションファイル確認 ===\n",
            "  スパース点群データ: 利用可能\n",
            "  COLMAPデータ: 利用可能\n"
          ]
        }
      ],
      "source": [
        "# 4. Colab環境でのデータ検証\n",
        "print(\"=== Google Colab データ検証 ===\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Colab環境でのパス設定\n",
        "processed_path = '/content/drive/MyDrive/processed'\n",
        "\n",
        "# 基本構造確認\n",
        "print(\"データ構造確認:\")\n",
        "if os.path.exists(processed_path):\n",
        "    !find /content/drive/MyDrive/processed -type f | head -15\n",
        "else:\n",
        "    print(\"processed/ フォルダが見つかりません\")\n",
        "    print(\"セル2でのアップロードを確認してください\")\n",
        "\n",
        "# transforms.json 詳細確認\n",
        "print(\"\\n=== transforms.json 検証 ===\")\n",
        "transforms_path = os.path.join(processed_path, 'transforms.json')\n",
        "if os.path.exists(transforms_path):\n",
        "    print(\"transforms.json が見つかりました\")\n",
        "\n",
        "    try:\n",
        "        with open(transforms_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # 基本情報表示\n",
        "        print(f\"カメラ内部パラメータ確認:\")\n",
        "        if 'camera_angle_x' in data:\n",
        "            print(f\"  camera_angle_x: {data['camera_angle_x']}\")\n",
        "        if 'fl_x' in data:\n",
        "            print(f\"  focal length x: {data['fl_x']}\")\n",
        "\n",
        "        # フレーム情報確認\n",
        "        if 'frames' in data:\n",
        "            frame_count = len(data['frames'])\n",
        "            print(f\"  総フレーム数: {frame_count}\")\n",
        "\n",
        "            if frame_count > 0:\n",
        "                sample_frame = data['frames'][0]\n",
        "                sample_path = sample_frame.get('file_path', '')\n",
        "                print(f\"  サンプルパス: {sample_path}\")\n",
        "\n",
        "                # パス正規化確認\n",
        "                if sample_path.startswith('./'):\n",
        "                    print(\"  パス形式: 正規化済み (Colab対応)\")\n",
        "                else:\n",
        "                    print(\"  警告: パス形式が正規化されていません\")\n",
        "\n",
        "                # 実際のファイル存在確認\n",
        "                full_path = os.path.join(processed_path, sample_path.lstrip('./'))\n",
        "                if os.path.exists(full_path):\n",
        "                    print(\"  ファイル存在確認: OK\")\n",
        "                else:\n",
        "                    print(f\"  警告: ファイルが見つかりません: {full_path}\")\n",
        "\n",
        "        print(\"transforms.json の検証が完了しました\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"transforms.json 読み込みエラー: {e}\")\n",
        "else:\n",
        "    print(\"transforms.json が見つかりません\")\n",
        "\n",
        "# 画像データ確認\n",
        "print(\"\\n=== 画像データ検証 ===\")\n",
        "images_path = os.path.join(processed_path, 'images')\n",
        "if os.path.exists(images_path):\n",
        "    all_files = os.listdir(images_path)\n",
        "    jpg_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg'))]\n",
        "    png_files = [f for f in all_files if f.lower().endswith('.png')]\n",
        "\n",
        "    total_images = len(jpg_files) + len(png_files)\n",
        "    print(f\"画像ファイル統計:\")\n",
        "    print(f\"  JPG/JPEG: {len(jpg_files)} 枚\")\n",
        "    print(f\"  PNG: {len(png_files)} 枚\")\n",
        "    print(f\"  合計: {total_images} 枚\")\n",
        "\n",
        "    if total_images > 0:\n",
        "        # サンプル画像の詳細確認\n",
        "        sample_image = jpg_files[0] if jpg_files else png_files[0]\n",
        "        sample_path = os.path.join(images_path, sample_image)\n",
        "        file_size = os.path.getsize(sample_path) / 1024  # KB\n",
        "        print(f\"  サンプル画像: {sample_image} ({file_size:.1f} KB)\")\n",
        "\n",
        "        # Colab学習推奨設定の判定\n",
        "        if total_images >= 20:\n",
        "            print(\"Colab学習に適した画像数です\")\n",
        "        elif total_images >= 10:\n",
        "            print(\"学習可能ですが、より多くの画像があると品質が向上します\")\n",
        "        else:\n",
        "            print(\"警告: 画像数が少なく、学習結果の品質が低い可能性があります\")\n",
        "\n",
        "        print(f\"\\nColab環境でのデータ検証完了\")\n",
        "        print(f\"学習準備が整いました！\")\n",
        "    else:\n",
        "        print(\"画像ファイルが見つかりません\")\n",
        "else:\n",
        "    print(\"images/ フォルダが見つかりません\")\n",
        "\n",
        "# その他のファイル確認\n",
        "print(\"\\n=== オプションファイル確認 ===\")\n",
        "additional_files = [\n",
        "    ('sparse_pc.ply', 'スパース点群データ'),\n",
        "    ('colmap', 'COLMAPデータ')\n",
        "]\n",
        "\n",
        "for file_name, description in additional_files:\n",
        "    file_path = os.path.join(processed_path, file_name)\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"  {description}: 利用可能\")\n",
        "    else:\n",
        "        print(f\"  {description}: なし（オプション）\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ad6ec7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ad6ec7",
        "outputId": "0014073f-c931-41ff-d12c-1abc548c2bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Google Colab 最適化学習実行 ===\n",
            "Colab学習環境確認:\n",
            "  GPU: Tesla T4\n",
            "  VRAM: 14.7 GB\n",
            "  T4 GPU検出: 軽量設定を推奨\n",
            "\n",
            "推奨イテレーション数: 10000\n",
            "学習時間は画像数とGPUにより5分〜60分程度です\n",
            "Ctrl+C で安全に中断できます（途中保存あり）\n",
            "\n",
            "実行コマンド: ns-train nerfacto --data /content/drive/MyDrive/processed --output-dir /content/drive/MyDrive/processed/outputs/ --max-num-iterations 10000 --steps-per-save 1000 --steps-per-eval-image 500 --steps-per-eval-batch 500 --logging.steps-per-log 100\n",
            "\n",
            "2025-08-29 14:22:45.089541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756477365.111421    6477 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756477365.119458    6477 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756477365.137810    6477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477365.137838    6477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477365.137842    6477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477365.137844    6477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-29 14:22:45.145404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/field_components/activations.py:32: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float32)\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/field_components/activations.py:38: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "[14:23:07] Using --data alias for --data.pipeline.datamanager.data                                          train.py:230\n",
            "──────────────────────────────────────────────────────── Config ────────────────────────────────────────────────────────\n",
            "TrainerConfig(\n",
            "    _target=<class 'nerfstudio.engine.trainer.Trainer'>,\n",
            "    output_dir=PosixPath('/content/drive/MyDrive/processed/outputs'),\n",
            "    method_name='nerfacto',\n",
            "    experiment_name=None,\n",
            "    project_name='nerfstudio-project',\n",
            "    timestamp='2025-08-29_142307',\n",
            "    machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),\n",
            "    logging=LoggingConfig(\n",
            "        relative_log_dir=PosixPath('.'),\n",
            "        steps_per_log=100,\n",
            "        max_buffer_size=20,\n",
            "        local_writer=LocalWriterConfig(\n",
            "            _target=<class 'nerfstudio.utils.writer.LocalWriter'>,\n",
            "            enable=True,\n",
            "            stats_to_track=(\n",
            "                <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,\n",
            "                <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,\n",
            "                <EventName.CURR_TEST_PSNR: 'Test PSNR'>,\n",
            "                <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,\n",
            "                <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,\n",
            "                <EventName.ETA: 'ETA (time)'>\n",
            "            ),\n",
            "            max_log_size=10\n",
            "        ),\n",
            "        profiler='basic'\n",
            "    ),\n",
            "    viewer=ViewerConfig(\n",
            "        relative_log_filename='viewer_log_filename.txt',\n",
            "        websocket_port=None,\n",
            "        websocket_port_default=7007,\n",
            "        websocket_host='0.0.0.0',\n",
            "        num_rays_per_chunk=32768,\n",
            "        max_num_display_images=512,\n",
            "        quit_on_train_completion=False,\n",
            "        image_format='jpeg',\n",
            "        jpeg_quality=75,\n",
            "        make_share_url=False,\n",
            "        camera_frustum_scale=0.1,\n",
            "        default_composite_depth=True\n",
            "    ),\n",
            "    pipeline=VanillaPipelineConfig(\n",
            "        _target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>,\n",
            "        datamanager=ParallelDataManagerConfig(\n",
            "            _target=<class 'nerfstudio.data.datamanagers.parallel_datamanager.ParallelDataManager'>,\n",
            "            data=PosixPath('/content/drive/MyDrive/processed'),\n",
            "            masks_on_gpu=False,\n",
            "            images_on_gpu=False,\n",
            "            dataparser=NerfstudioDataParserConfig(\n",
            "                _target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>,\n",
            "                data=PosixPath('.'),\n",
            "                scale_factor=1.0,\n",
            "                downscale_factor=None,\n",
            "                scene_scale=1.0,\n",
            "                orientation_method='up',\n",
            "                center_method='poses',\n",
            "                auto_scale_poses=True,\n",
            "                eval_mode='fraction',\n",
            "                train_split_fraction=0.9,\n",
            "                eval_interval=8,\n",
            "                depth_unit_scale_factor=0.001,\n",
            "                mask_color=None,\n",
            "                load_3D_points=False\n",
            "            ),\n",
            "            train_num_rays_per_batch=4096,\n",
            "            train_num_images_to_sample_from=-1,\n",
            "            train_num_times_to_repeat_images=-1,\n",
            "            eval_num_rays_per_batch=4096,\n",
            "            eval_num_images_to_sample_from=-1,\n",
            "            eval_num_times_to_repeat_images=-1,\n",
            "            eval_image_indices=(0,),\n",
            "            collate_fn=<function nerfstudio_collate at 0x7922419ac7c0>,\n",
            "            camera_res_scale_factor=1.0,\n",
            "            patch_size=1,\n",
            "            camera_optimizer=None,\n",
            "            pixel_sampler=PixelSamplerConfig(\n",
            "                _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,\n",
            "                num_rays_per_batch=4096,\n",
            "                keep_full_image=False,\n",
            "                is_equirectangular=False,\n",
            "                ignore_mask=False,\n",
            "                fisheye_crop_radius=None,\n",
            "                rejection_sample_mask=True,\n",
            "                max_num_iterations=100\n",
            "            ),\n",
            "            num_processes=1,\n",
            "            queue_size=2,\n",
            "            max_thread_workers=None\n",
            "        ),\n",
            "        model=NerfactoModelConfig(\n",
            "            _target=<class 'nerfstudio.models.nerfacto.NerfactoModel'>,\n",
            "            enable_collider=True,\n",
            "            collider_params={'near_plane': 2.0, 'far_plane': 6.0},\n",
            "            loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},\n",
            "            eval_num_rays_per_chunk=32768,\n",
            "            prompt=None,\n",
            "            near_plane=0.05,\n",
            "            far_plane=1000.0,\n",
            "            background_color='last_sample',\n",
            "            hidden_dim=64,\n",
            "            hidden_dim_color=64,\n",
            "            hidden_dim_transient=64,\n",
            "            num_levels=16,\n",
            "            base_res=16,\n",
            "            max_res=2048,\n",
            "            log2_hashmap_size=19,\n",
            "            features_per_level=2,\n",
            "            num_proposal_samples_per_ray=(256, 96),\n",
            "            num_nerf_samples_per_ray=48,\n",
            "            proposal_update_every=5,\n",
            "            proposal_warmup=5000,\n",
            "            num_proposal_iterations=2,\n",
            "            use_same_proposal_network=False,\n",
            "            proposal_net_args_list=[\n",
            "                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 128, 'use_linear': False},\n",
            "                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256, 'use_linear': False}\n",
            "            ],\n",
            "            proposal_initial_sampler='piecewise',\n",
            "            interlevel_loss_mult=1.0,\n",
            "            distortion_loss_mult=0.002,\n",
            "            orientation_loss_mult=0.0001,\n",
            "            pred_normal_loss_mult=0.001,\n",
            "            use_proposal_weight_anneal=True,\n",
            "            use_appearance_embedding=True,\n",
            "            use_average_appearance_embedding=True,\n",
            "            proposal_weights_anneal_slope=10.0,\n",
            "            proposal_weights_anneal_max_num_iters=1000,\n",
            "            use_single_jitter=True,\n",
            "            predict_normals=False,\n",
            "            disable_scene_contraction=False,\n",
            "            use_gradient_scaling=False,\n",
            "            implementation='tcnn',\n",
            "            appearance_embed_dim=32,\n",
            "            average_init_density=0.01,\n",
            "            camera_optimizer=CameraOptimizerConfig(\n",
            "                _target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>,\n",
            "                mode='SO3xR3',\n",
            "                trans_l2_penalty=0.01,\n",
            "                rot_l2_penalty=0.001,\n",
            "                optimizer=None,\n",
            "                scheduler=None\n",
            "            )\n",
            "        )\n",
            "    ),\n",
            "    optimizers={\n",
            "        'proposal_networks': {\n",
            "            'optimizer': AdamOptimizerConfig(\n",
            "                _target=<class 'torch.optim.adam.Adam'>,\n",
            "                lr=0.01,\n",
            "                eps=1e-15,\n",
            "                max_norm=None,\n",
            "                weight_decay=0\n",
            "            ),\n",
            "            'scheduler': ExponentialDecaySchedulerConfig(\n",
            "                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
            "                lr_pre_warmup=1e-08,\n",
            "                lr_final=0.0001,\n",
            "                warmup_steps=0,\n",
            "                max_steps=200000,\n",
            "                ramp='cosine'\n",
            "            )\n",
            "        },\n",
            "        'fields': {\n",
            "            'optimizer': AdamOptimizerConfig(\n",
            "                _target=<class 'torch.optim.adam.Adam'>,\n",
            "                lr=0.01,\n",
            "                eps=1e-15,\n",
            "                max_norm=None,\n",
            "                weight_decay=0\n",
            "            ),\n",
            "            'scheduler': ExponentialDecaySchedulerConfig(\n",
            "                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
            "                lr_pre_warmup=1e-08,\n",
            "                lr_final=0.0001,\n",
            "                warmup_steps=0,\n",
            "                max_steps=200000,\n",
            "                ramp='cosine'\n",
            "            )\n",
            "        },\n",
            "        'camera_opt': {\n",
            "            'optimizer': AdamOptimizerConfig(\n",
            "                _target=<class 'torch.optim.adam.Adam'>,\n",
            "                lr=0.001,\n",
            "                eps=1e-15,\n",
            "\n",
            "[Colab進捗] 経過時間: 0.4分, 処理行数: 200\n",
            "                max_norm=None,\n",
            "                weight_decay=0\n",
            "            ),\n",
            "            'scheduler': ExponentialDecaySchedulerConfig(\n",
            "                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
            "                lr_pre_warmup=1e-08,\n",
            "                lr_final=0.0001,\n",
            "                warmup_steps=0,\n",
            "                max_steps=5000,\n",
            "                ramp='cosine'\n",
            "            )\n",
            "        }\n",
            "    },\n",
            "    vis='viewer',\n",
            "    data=PosixPath('/content/drive/MyDrive/processed'),\n",
            "    prompt=None,\n",
            "    relative_model_dir=PosixPath('nerfstudio_models'),\n",
            "    load_scheduler=True,\n",
            "    steps_per_save=1000,\n",
            "    steps_per_eval_batch=500,\n",
            "    steps_per_eval_image=500,\n",
            "    steps_per_eval_all_images=25000,\n",
            "    max_num_iterations=10000,\n",
            "    mixed_precision=True,\n",
            "    use_grad_scaler=False,\n",
            "    save_only_latest_checkpoint=True,\n",
            "    load_dir=None,\n",
            "    load_step=None,\n",
            "    load_config=None,\n",
            "    load_checkpoint=None,\n",
            "    log_gradients=False,\n",
            "    gradient_accumulation_steps={},\n",
            "    start_paused=False\n",
            ")\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "           Saving config to:                                                                    experiment_config.py:136\n",
            "           /content/drive/MyDrive/processed/outputs/processed/nerfacto/2025-08-29_142307/config                         \n",
            "           .yml                                                                                                         \n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/engine/trainer.py:137: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler(enabled=self.use_grad_scaler)\n",
            "           Saving checkpoints to:                                                                         trainer.py:142\n",
            "           /content/drive/MyDrive/processed/outputs/processed/nerfacto/2025-08-29_142307/nerfstudio_model               \n",
            "           s                                                                                                            \n",
            "           Auto image downscale factor of 1                                                 nerfstudio_dataparser.py:484\n",
            "            Dataset is overriding orientation method to none                                nerfstudio_dataparser.py:232\n",
            "            Dataset is overriding orientation method to none                                nerfstudio_dataparser.py:232\n",
            "            Dataset is overriding orientation method to none                                nerfstudio_dataparser.py:232\n",
            "2025-08-29 14:23:11.151576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756477391.186378    6610 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756477391.202435    6610 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756477391.226150    6610 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477391.226188    6610 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477391.226191    6610 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477391.226193    6610 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/field_components/activations.py:32: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float32)\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/field_components/activations.py:38: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "Started threads\n",
            "Setting up evaluation dataset...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Caching all 4 images.\n",
            "\n",
            "Loading data batch ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/cameras.py:601: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  fx, fy = self.fx[true_indices].squeeze(-1), self.fy[true_indices].squeeze(-1)  # (num_rays,)\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/cameras.py:602: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  cx, cy = self.cx[true_indices].squeeze(-1), self.cy[true_indices].squeeze(-1)  # (num_rays,)\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/cameras.py:639: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  distortion_params = self.distortion_params[true_indices]\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/cameras.py:647: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  mask = (self.camera_type[true_indices] != CameraType.EQUIRECTANGULAR.value).squeeze(-1)  # (num_rays)\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/cameras.py:669: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  c2w = self.camera_to_worlds[true_indices]\n",
            "/usr/local/lib/python3.12/dist-packages/nerfstudio/cameras/cameras.py:783: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  mask = (self.camera_type[true_indices] == CameraType.PERSPECTIVE.value).squeeze(-1)  # (num_rays)\n",
            "\n",
            "WARNING: Using a slow implementation for the SHEncoding module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the NeRFEncoding module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the MLPWithHashEncoding module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the MLP module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the HashEncoding module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the MLP module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the HashEncoding module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "\n",
            "WARNING: Using a slow implementation for the MLP module. \n",
            "🏃 🏃 Install tcnn for speedups 🏃 🏃\n",
            "pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "\n",
            "  0%|          | 0.00/233M [00:00<?, ?B/s]\n",
            "  7%|▋         | 15.6M/233M [00:00<00:01, 164MB/s]\n",
            " 16%|█▌        | 36.9M/233M [00:00<00:01, 198MB/s]\n",
            " 24%|██▍       | 55.9M/233M [00:00<00:00, 195MB/s]\n",
            " 33%|███▎      | 76.1M/233M [00:00<00:00, 202MB/s]\n",
            " 41%|████      | 95.4M/233M [00:00<00:00, 163MB/s]\n",
            " 49%|████▉     | 114M/233M [00:00<00:00, 173MB/s] \n",
            " 56%|█████▋    | 132M/233M [00:00<00:00, 168MB/s]\n",
            " 64%|██████▎   | 148M/233M [00:00<00:00, 169MB/s]\n",
            " 72%|███████▏  | 167M/233M [00:00<00:00, 178MB/s]\n",
            " 79%|███████▉  | 184M/233M [00:01<00:00, 178MB/s]\n",
            " 87%|████████▋ | 204M/233M [00:01<00:00, 184MB/s]\n",
            " 96%|█████████▌| 224M/233M [00:01<00:00, 193MB/s]\n",
            "100%|██████████| 233M/233M [00:01<00:00, 183MB/s]\n",
            "╭─────────────── viser ───────────────╮\n",
            "│             ╷                       │\n",
            "│   HTTP      │ http://0.0.0.0:7007   │\n",
            "│   Websocket │ ws://0.0.0.0:7007     │\n",
            "│             ╵                       │\n",
            "╰─────────────────────────────────────╯\n",
            "[NOTE] Not running eval iterations since only viewer is enabled.\n",
            "Use --vis {wandb, tensorboard, viewer+wandb, viewer+tensorboard} to run with eval.\n",
            "No Nerfstudio checkpoint to load, so training from scratch.\n",
            "Disabled comet/tensorboard/wandb event writers\n",
            "[14:23:38] Printing max of 10 lines. Set flag --logging.local-writer.max-log-size=0 to disable line        writer.py:449\n",
            "           wrapping.                                                                                                    \n"
          ]
        }
      ],
      "source": [
        "# 5. Google Colab最適化 nerfstudio学習\n",
        "print(\"=== Google Colab 最適化学習実行 ===\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import threading\n",
        "import torch\n",
        "import glob\n",
        "\n",
        "# Colab環境確認\n",
        "print(\"Colab学習環境確認:\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"  GPU: {gpu_name}\")\n",
        "    print(f\"  VRAM: {gpu_memory:.1f} GB\")\n",
        "\n",
        "    # GPU種別に応じた推奨設定\n",
        "    if \"T4\" in gpu_name:\n",
        "        recommended_iterations = 10000\n",
        "        print(f\"  T4 GPU検出: 軽量設定を推奨\")\n",
        "    elif \"A100\" in gpu_name or \"V100\" in gpu_name:\n",
        "        recommended_iterations = 30000\n",
        "        print(f\"  高性能GPU検出: 高品質設定が可能\")\n",
        "    else:\n",
        "        recommended_iterations = 15000\n",
        "        print(f\"  標準設定を使用\")\n",
        "else:\n",
        "    recommended_iterations = 5000\n",
        "    print(\"  CPU学習: 最小設定（非推奨）\")\n",
        "\n",
        "print(f\"\\n推奨イテレーション数: {recommended_iterations}\")\n",
        "print(\"学習時間は画像数とGPUにより5分〜60分程度です\")\n",
        "print(\"Ctrl+C で安全に中断できます（途中保存あり）\\n\")\n",
        "\n",
        "# Colab固有のGPU監視機能\n",
        "def monitor_colab_resources():\n",
        "    \"\"\"Colab環境のリソース監視\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        while True:\n",
        "            try:\n",
        "                # GPU メモリ使用量\n",
        "                memory_used = torch.cuda.memory_allocated(0) / 1024**3\n",
        "                memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "                memory_percent = (memory_used / memory_total) * 100\n",
        "\n",
        "                # CPU とメモリ（簡易表示）\n",
        "                print(f\"GPU: {memory_used:.1f}/{memory_total:.1f}GB ({memory_percent:.1f}%)\", end='\\r')\n",
        "                time.sleep(30)\n",
        "            except:\n",
        "                break\n",
        "\n",
        "# Colab最適化された学習コマンド\n",
        "cmd = [\n",
        "    \"ns-train\",\n",
        "    \"nerfacto\",  # Colab環境で最も安定したメソッド\n",
        "    \"--data\", \"/content/drive/MyDrive/processed\",\n",
        "    \"--output-dir\", \"/content/drive/MyDrive/processed/outputs/\",\n",
        "    \"--max-num-iterations\", str(recommended_iterations),\n",
        "    \"--steps-per-save\", \"1000\",  # Colab環境では頻繁に保存\n",
        "    \"--steps-per-eval-image\", \"500\",  # 評価頻度\n",
        "    \"--steps-per-eval-batch\", \"500\",  # バッチ評価\n",
        "    \"--logging.steps-per-log\", \"100\"  # ログ頻度（Colab表示用）\n",
        "]\n",
        "\n",
        "# GPU メモリに応じたバッチサイズ調整\n",
        "if torch.cuda.is_available():\n",
        "    memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    if memory_gb < 12:  # T4など\n",
        "        cmd.extend([\"--pipeline.datamanager.train-num-rays-per-batch\", \"2048\"])\n",
        "        print(\"GPU メモリ使用量を最適化しました（小メモリ GPU 対応）\")\n",
        "    elif memory_gb >= 24:  # A100など\n",
        "        cmd.extend([\"--pipeline.datamanager.train-num-rays-per-batch\", \"8192\"])\n",
        "        print(\"高メモリ GPU 用に最適化しました\")\n",
        "\n",
        "print(f\"実行コマンド: {' '.join(cmd)}\\n\")\n",
        "\n",
        "# リソース監視開始\n",
        "if torch.cuda.is_available():\n",
        "    monitor_thread = threading.Thread(target=monitor_colab_resources, daemon=True)\n",
        "    monitor_thread.start()\n",
        "\n",
        "# 学習実行\n",
        "start_time = time.time()\n",
        "process = subprocess.Popen(\n",
        "    cmd,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True,\n",
        "    bufsize=1,\n",
        "    cwd=\"/content/drive/MyDrive/processed\"  # Colab作業ディレクトリ\n",
        ")\n",
        "\n",
        "try:\n",
        "    line_count = 0\n",
        "    for line in process.stdout:\n",
        "        print(line, end=\"\")\n",
        "        sys.stdout.flush()\n",
        "        line_count += 1\n",
        "\n",
        "        # Colab用の進捗表示（200行ごと）\n",
        "        if line_count % 200 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"\\n[Colab進捗] 経過時間: {elapsed/60:.1f}分, 処理行数: {line_count}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\\n学習を中断しました（Colab環境）\")\n",
        "    process.terminate()\n",
        "    process.wait()\n",
        "\n",
        "    # 中断時の結果確認\n",
        "    print(\"中断時点での学習結果を確認中...\")\n",
        "    if os.path.exists(\"/content/drive/MyDrive/processed/outputs\"):\n",
        "        ckpt_files = glob.glob('/content/drive/MyDrive/processed/outputs/**/*.ckpt', recursive=True)\n",
        "        if ckpt_files:\n",
        "            print(f\"保存されたチェックポイント: {len(ckpt_files)} 個\")\n",
        "            latest_ckpt = max(ckpt_files, key=os.path.getctime)\n",
        "            print(f\"最新チェックポイント: {latest_ckpt}\")\n",
        "        else:\n",
        "            print(\"チェックポイントファイルが見つかりません\")\n",
        "\n",
        "# 学習完了処理\n",
        "process.wait()\n",
        "elapsed_total = time.time() - start_time\n",
        "\n",
        "print(f\"\\n=== Google Colab学習完了 ===\")\n",
        "print(f\"総学習時間: {elapsed_total/60:.1f}分\")\n",
        "print(f\"出力先: /content/drive/MyDrive/processed/outputs/\")\n",
        "\n",
        "# Colab環境での結果確認\n",
        "if os.path.exists(\"/content/drive/MyDrive/processed/outputs\"):\n",
        "    ckpt_files = glob.glob('/content/drive/MyDrive/processed/outputs/**/*.ckpt', recursive=True)\n",
        "    config_files = glob.glob('/content/drive/MyDrive/processed/outputs/**/config.yml', recursive=True)\n",
        "\n",
        "    print(f\"生成ファイル:\")\n",
        "    print(f\"  チェックポイント (.ckpt): {len(ckpt_files)} 個\")\n",
        "    print(f\"  設定ファイル (config.yml): {len(config_files)} 個\")\n",
        "\n",
        "    if ckpt_files and config_files:\n",
        "        print(\"\\nColab環境での学習が正常に完了しました！\")\n",
        "        print(\"次のセルでエクスポート処理を実行できます\")\n",
        "    else:\n",
        "        print(\"\\n学習結果が不完全です\")\n",
        "        print(\"ランタイムエラーがないか確認してください\")\n",
        "else:\n",
        "    print(\"outputs/ フォルダが作成されませんでした\")\n",
        "    print(\"学習コマンドの実行に問題があった可能性があります\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee1e516",
      "metadata": {
        "id": "cee1e516"
      },
      "outputs": [],
      "source": [
        "# 6. 学習結果確認\n",
        "print(\"=== 学習結果確認 ===\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# 出力フォルダの存在確認\n",
        "if os.path.exists(\"/content/drive/MyDrive/processed/outputs\"):\n",
        "    print(\"/content/drive/MyDrive/processed/outputs/ フォルダが見つかりました\")\n",
        "\n",
        "    # チェックポイントファイル確認\n",
        "    ckpt_files = glob.glob('outputs/**/*.ckpt', recursive=True)\n",
        "    config_files = glob.glob('outputs/**/config.yml', recursive=True)\n",
        "\n",
        "    print(f\"チェックポイントファイル: {len(ckpt_files)} 個\")\n",
        "    if ckpt_files:\n",
        "        for ckpt in ckpt_files:\n",
        "            size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
        "            print(f\"  - {ckpt} ({size_mb:.1f} MB)\")\n",
        "\n",
        "    print(f\"設定ファイル: {len(config_files)} 個\")\n",
        "    if config_files:\n",
        "        for config in config_files:\n",
        "            print(f\"  - {config}\")\n",
        "\n",
        "    # フォルダ構造確認\n",
        "    print(\"\\n=== outputs/ フォルダ構造 ===\")\n",
        "    for root, dirs, files in os.walk(\"/content/drive/MyDrive/processed/outputs\"):\n",
        "        level = root.replace(\"/content/drive/MyDrive/processed/outputs\", \"\").count(os.sep)\n",
        "        indent = \" \" * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = \" \" * 2 * (level + 1)\n",
        "        for file in files[:3]:  # 最初の3ファイルのみ表示\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"{subindent}... 他 {len(files)-3} ファイル\")\n",
        "\n",
        "    if ckpt_files and config_files:\n",
        "        print(\"\\n学習完了！エクスポート処理に進めます\")\n",
        "    else:\n",
        "        print(\"\\n学習結果が不完全です。セル5を再実行してください\")\n",
        "\n",
        "else:\n",
        "    print(\"outputs/ フォルダが見つかりません\")\n",
        "    print(\"セル5で学習を実行してください\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb0f744",
      "metadata": {
        "id": "1cb0f744"
      },
      "outputs": [],
      "source": [
        "# 7. Google Colab最適化エクスポート\n",
        "print(\"=== Google Colab 最適化エクスポート ===\")\n",
        "print(\"Colab環境で安定動作する3形式でエクスポートします\")\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Colab環境での設定ファイル検索\n",
        "config_files = glob.glob('/content/drive/MyDrive/processed/outputs/**/config.yml', recursive=True)\n",
        "\n",
        "if not config_files:\n",
        "    print(\"config.yml ファイルが見つかりません\")\n",
        "    print(\"セル5で学習を完了してから実行してください\")\n",
        "else:\n",
        "    config_path = config_files[0]\n",
        "    print(f\"設定ファイル: {config_path}\")\n",
        "\n",
        "    # Colab環境用エクスポートディレクトリ\n",
        "    export_dir = \"/content/drive/MyDrive/processed/exports\"\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "    # Colab環境で動作確認済みのエクスポート形式\n",
        "    export_options = [\n",
        "        (\"pointcloud\", \"3D点群\", \"MeshLab等で表示可能な.plyファイル\"),\n",
        "        (\"cameras\", \"カメラ軌道\", \"撮影経路を記録した.jsonファイル\"),\n",
        "        (\"splat\", \"3D Gaussian\", \"高品質3D表現データ\")\n",
        "    ]\n",
        "\n",
        "    successful_exports = []\n",
        "    print(f\"\\nColab環境での{len(export_options)}形式エクスポート開始...\")\n",
        "\n",
        "    for option, name, description in export_options:\n",
        "        output_path = os.path.join(export_dir, option)\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n{name}をエクスポート中...\")\n",
        "        print(f\"  形式: {description}\")\n",
        "\n",
        "        # Colab環境用エクスポートコマンド\n",
        "        cmd = [\n",
        "            \"ns-export\", option,\n",
        "            \"--load-config\", config_path,\n",
        "            \"--output-dir\", output_path\n",
        "        ]\n",
        "\n",
        "        # Colab環境用の環境変数設定\n",
        "        export_env = os.environ.copy()\n",
        "        export_env['PYTHONWARNINGS'] = 'ignore'\n",
        "        export_env['TORCH_WARN'] = '0'\n",
        "        export_env['CUDA_VISIBLE_DEVICES'] = '0'  # Colab GPU指定\n",
        "\n",
        "        try:\n",
        "            print(f\"  実行中: {' '.join(cmd)}\")\n",
        "            result = subprocess.run(\n",
        "                cmd,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=600,  # Colab環境では10分でタイムアウト\n",
        "                env=export_env,\n",
        "                cwd=\"/content/drive/MyDrive/processed\"\n",
        "            )\n",
        "\n",
        "            # エクスポート結果確認\n",
        "            if os.path.exists(output_path):\n",
        "                generated_files = [f for f in os.listdir(output_path)\n",
        "                                 if os.path.isfile(os.path.join(output_path, f))]\n",
        "\n",
        "                if generated_files:\n",
        "                    print(f\"  ✓ {name}エクスポート成功！\")\n",
        "                    successful_exports.append((option, name, output_path))\n",
        "\n",
        "                    # ファイル詳細表示\n",
        "                    total_size = 0\n",
        "                    for i, file in enumerate(generated_files[:3]):  # 最初の3ファイル表示\n",
        "                        file_path = os.path.join(output_path, file)\n",
        "                        file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
        "                        total_size += file_size\n",
        "                        print(f\"    - {file} ({file_size:.2f} MB)\")\n",
        "\n",
        "                    if len(generated_files) > 3:\n",
        "                        remaining_files = generated_files[3:]\n",
        "                        remaining_size = sum(os.path.getsize(os.path.join(output_path, f))\n",
        "                                           for f in remaining_files) / (1024 * 1024)\n",
        "                        total_size += remaining_size\n",
        "                        print(f\"    - ...他 {len(remaining_files)} ファイル ({remaining_size:.2f} MB)\")\n",
        "\n",
        "                    print(f\"    合計: {len(generated_files)} ファイル, {total_size:.2f} MB\")\n",
        "                else:\n",
        "                    print(f\"  ✗ {name}: ファイル生成に失敗\")\n",
        "                    if result.stderr:\n",
        "                        # Colabで重要なエラーのみ表示\n",
        "                        error_lines = [line for line in result.stderr.split('\\n')\n",
        "                                     if 'error' in line.lower() or 'exception' in line.lower()]\n",
        "                        for error_line in error_lines[:2]:  # 最初の2行のみ\n",
        "                            print(f\"    エラー: {error_line.strip()}\")\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"  ✗ {name}エクスポートがタイムアウトしました（10分）\")\n",
        "            print(f\"    Colab環境では処理時間に制限があります\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ {name}エクスポート処理でエラー: {e}\")\n",
        "\n",
        "    # Colab環境での結果サマリー\n",
        "    print(f\"\\n=== Colabエクスポート結果 ===\")\n",
        "    if successful_exports:\n",
        "        print(f\"成功: {len(successful_exports)}/{len(export_options)} 形式\")\n",
        "        print(f\"エクスポート先: {export_dir}\")\n",
        "\n",
        "        for option, name, path in successful_exports:\n",
        "            file_count = len([f for f in os.listdir(path)\n",
        "                             if os.path.isfile(os.path.join(path, f))])\n",
        "            folder_size = sum(os.path.getsize(os.path.join(path, f))\n",
        "                             for f in os.listdir(path)\n",
        "                             if os.path.isfile(os.path.join(path, f))) / (1024 * 1024)\n",
        "            print(f\"  ✓ {name}: {file_count} ファイル ({folder_size:.1f} MB)\")\n",
        "\n",
        "        print(f\"\\n次のステップ:\")\n",
        "        print(f\"  - セル9: ファイルダウンロード\")\n",
        "        print(f\"  - セル10: Colab内3Dビューワ\")\n",
        "    else:\n",
        "        print(\"すべてのエクスポートが失敗しました\")\n",
        "        print(\"セル8の代替エクスポート方法をお試しください\")\n",
        "\n",
        "print(f\"\\nColab環境でのエクスポート処理が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7a83d4",
      "metadata": {
        "id": "bb7a83d4"
      },
      "outputs": [],
      "source": [
        "# 8. Google Colab代替エクスポート（セーフモード）\n",
        "print(\"=== Google Colab 代替エクスポート ===\")\n",
        "print(\"エクスポートコマンドが失敗した場合のColab用直接ファイルアクセス\")\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Colab環境でのoutputsディレクトリ確認\n",
        "outputs_dir = '/content/drive/MyDrive/processed/outputs'\n",
        "if os.path.exists(outputs_dir):\n",
        "    # Colab用代替エクスポートディレクトリ\n",
        "    alt_export_dir = \"/content/drive/MyDrive/processed/alternative_exports\"\n",
        "    os.makedirs(alt_export_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Colab環境: {outputs_dir} から重要ファイルを抽出中...\")\n",
        "\n",
        "    # 1. チェックポイントファイル収集\n",
        "    ckpt_files = glob.glob(f'{outputs_dir}/**/*.ckpt', recursive=True)\n",
        "    if ckpt_files:\n",
        "        ckpt_dir = os.path.join(alt_export_dir, \"checkpoints\")\n",
        "        os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nチェックポイントファイル処理中...\")\n",
        "        for ckpt_file in ckpt_files:\n",
        "            dest_file = os.path.join(ckpt_dir, os.path.basename(ckpt_file))\n",
        "            shutil.copy2(ckpt_file, dest_file)\n",
        "            size_mb = os.path.getsize(dest_file) / (1024 * 1024)\n",
        "            print(f\"  ✓ {os.path.basename(ckpt_file)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "    # 2. 設定ファイル収集\n",
        "    config_files = glob.glob(f'{outputs_dir}/**/config.yml', recursive=True)\n",
        "    if config_files:\n",
        "        config_dir = os.path.join(alt_export_dir, \"configs\")\n",
        "        os.makedirs(config_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n設定ファイル処理中...\")\n",
        "        for i, config_file in enumerate(config_files):\n",
        "            dest_name = f\"config_{i+1}.yml\"\n",
        "            dest_file = os.path.join(config_dir, dest_name)\n",
        "            shutil.copy2(config_file, dest_file)\n",
        "            print(f\"  ✓ {dest_name}\")\n",
        "\n",
        "    # 3. 学習ログとメトリクス収集\n",
        "    log_extensions = ['*.json', '*.txt', '*.csv']\n",
        "    log_files = []\n",
        "    for ext in log_extensions:\n",
        "        log_files.extend(glob.glob(f'{outputs_dir}/**/{ext}', recursive=True))\n",
        "\n",
        "    if log_files:\n",
        "        logs_dir = os.path.join(alt_export_dir, \"logs\")\n",
        "        os.makedirs(logs_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nログファイル処理中...\")\n",
        "        colab_size_limit = 50 * 1024 * 1024  # Colab環境では50MB制限\n",
        "        total_size = 0\n",
        "\n",
        "        for log_file in log_files[:10]:  # Colab環境では最大10ファイル\n",
        "            file_size = os.path.getsize(log_file)\n",
        "            if total_size + file_size < colab_size_limit:\n",
        "                dest_file = os.path.join(logs_dir, os.path.basename(log_file))\n",
        "                shutil.copy2(log_file, dest_file)\n",
        "                size_mb = file_size / (1024 * 1024)\n",
        "                total_size += file_size\n",
        "                print(f\"  ✓ {os.path.basename(log_file)} ({size_mb:.2f} MB)\")\n",
        "            else:\n",
        "                print(f\"  - サイズ制限によりスキップ: {os.path.basename(log_file)}\")\n",
        "                break\n",
        "\n",
        "    # 4. Colab用メタデータ作成\n",
        "    colab_metadata = {\n",
        "        \"export_method\": \"colab_alternative_direct_copy\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"colab_environment\": True,\n",
        "        \"source_directory\": outputs_dir,\n",
        "        \"checkpoint_files\": len(ckpt_files) if ckpt_files else 0,\n",
        "        \"config_files\": len(config_files) if config_files else 0,\n",
        "        \"log_files\": len([f for f in os.listdir(logs_dir)]) if os.path.exists(logs_dir) else 0,\n",
        "        \"total_size_mb\": sum(os.path.getsize(os.path.join(root, file))\n",
        "                            for root, dirs, files in os.walk(alt_export_dir)\n",
        "                            for file in files) / (1024 * 1024),\n",
        "        \"notes\": \"Exported in Google Colab environment using direct file access\"\n",
        "    }\n",
        "\n",
        "    metadata_file = os.path.join(alt_export_dir, \"colab_export_info.json\")\n",
        "    with open(metadata_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(colab_metadata, f, indent=2)\n",
        "\n",
        "    # 5. Colab環境用ディレクトリ構造表示\n",
        "    print(f\"\\n=== Colab代替エクスポート完了 ===\")\n",
        "    print(f\"エクスポート先: {alt_export_dir}\")\n",
        "    print(f\"総サイズ: {colab_metadata['total_size_mb']:.1f} MB\")\n",
        "\n",
        "    print(f\"\\nフォルダ構造:\")\n",
        "    for root, dirs, files in os.walk(alt_export_dir):\n",
        "        level = root.replace(alt_export_dir, '').count(os.sep)\n",
        "        indent = '  ' * level\n",
        "        folder_name = os.path.basename(root) if root != alt_export_dir else 'alternative_exports'\n",
        "        print(f\"{indent}{folder_name}/\")\n",
        "\n",
        "        subindent = '  ' * (level + 1)\n",
        "        for file in files[:5]:  # 各フォルダ最大5ファイル表示\n",
        "            print(f\"{subindent}- {file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"{subindent}- ...他 {len(files)-5} ファイル\")\n",
        "\n",
        "    print(f\"\\nColab環境での使用方法:\")\n",
        "    print(f\"  - checkpoints/: ローカル環境でのnerfstudio読み込み用\")\n",
        "    print(f\"  - configs/: 学習設定確認・再現用\")\n",
        "    print(f\"  - logs/: 学習進捗分析・可視化用\")\n",
        "    print(f\"  - colab_export_info.json: Colab環境情報\")\n",
        "\n",
        "    print(f\"\\nファイルサイズがColab制限内に最適化されました\")\n",
        "\n",
        "else:\n",
        "    print(\"outputs/ フォルダが見つかりません\")\n",
        "    print(\"セル5でのColab学習を完了してから実行してください\")\n",
        "\n",
        "print(f\"\\nColab代替エクスポート処理が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de578fc5",
      "metadata": {
        "id": "de578fc5"
      },
      "outputs": [],
      "source": [
        "# 10. Google Colab品質確認＆可視化\n",
        "print(\"=== Google Colab 学習結果確認 ===\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Colab環境での結果ディレクトリ確認\n",
        "outputs_dir = '/content/drive/MyDrive/processed/outputs'\n",
        "\n",
        "if os.path.exists(outputs_dir):\n",
        "    print(f\"Colab環境: {outputs_dir} の学習結果を確認中...\")\n",
        "\n",
        "    # 1. Colab学習メトリクスの確認\n",
        "    experiment_dirs = [d for d in os.listdir(outputs_dir)\n",
        "                      if os.path.isdir(os.path.join(outputs_dir, d))]\n",
        "\n",
        "    if experiment_dirs:\n",
        "        latest_experiment = sorted(experiment_dirs)[-1]\n",
        "        exp_dir = os.path.join(outputs_dir, latest_experiment)\n",
        "        print(f\"\\n最新実験ディレクトリ: {latest_experiment}\")\n",
        "\n",
        "        # 2. Colab学習統計情報\n",
        "        config_file = os.path.join(exp_dir, 'config.yml')\n",
        "        if os.path.exists(config_file):\n",
        "            print(f\"\\n=== Colab学習設定 ===\")\n",
        "            with open(config_file, 'r') as f:\n",
        "                config_content = f.read()[:1000]  # Colab表示用に制限\n",
        "                print(config_content[:500] + \"...\" if len(config_content) > 500 else config_content)\n",
        "\n",
        "        # 3. Colabメトリクス可視化\n",
        "        metrics_files = glob.glob(os.path.join(exp_dir, '**/*metrics*.json'), recursive=True)\n",
        "        if metrics_files:\n",
        "            print(f\"\\n=== Colab学習メトリクス可視化 ===\")\n",
        "\n",
        "            # Colab用サンプルメトリクス可視化\n",
        "            plt.figure(figsize=(12, 4))\n",
        "\n",
        "            try:\n",
        "                with open(metrics_files[0], 'r') as f:\n",
        "                    for i, line in enumerate(f):\n",
        "                        if i > 100:  # Colab環境では100行制限\n",
        "                            break\n",
        "                        data = json.loads(line)\n",
        "                        if 'step' in data and 'loss' in data:\n",
        "                            plt.subplot(1, 3, 1)\n",
        "                            plt.plot(data['step'], data['loss'], 'b.', alpha=0.5)\n",
        "                            plt.title('Training Loss (Colab)')\n",
        "                            plt.xlabel('Step')\n",
        "                            plt.ylabel('Loss')\n",
        "\n",
        "                            if 'psnr' in data:\n",
        "                                plt.subplot(1, 3, 2)\n",
        "                                plt.plot(data['step'], data['psnr'], 'g.', alpha=0.5)\n",
        "                                plt.title('PSNR (Colab)')\n",
        "                                plt.xlabel('Step')\n",
        "                                plt.ylabel('PSNR (dB)')\n",
        "\n",
        "                            if 'learning_rate' in data:\n",
        "                                plt.subplot(1, 3, 3)\n",
        "                                plt.plot(data['step'], data['learning_rate'], 'r.', alpha=0.5)\n",
        "                                plt.title('Learning Rate (Colab)')\n",
        "                                plt.xlabel('Step')\n",
        "                                plt.ylabel('LR')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig('/content/drive/MyDrive/processed/colab_training_metrics.png', dpi=100, bbox_inches='tight')\n",
        "                plt.show()\n",
        "                print(\"Colab学習メトリクスの可視化が完了しました\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"メトリクス読み込みエラー (Colab互換性): {e}\")\n",
        "\n",
        "        # 4. Colab環境レンダリング画像確認\n",
        "        render_dirs = glob.glob(os.path.join(exp_dir, '**/renders'), recursive=True)\n",
        "        if render_dirs:\n",
        "            render_dir = render_dirs[0]\n",
        "            render_images = glob.glob(os.path.join(render_dir, '*.png'))[:6]  # Colab用6枚制限\n",
        "\n",
        "            if render_images:\n",
        "                print(f\"\\n=== Colab レンダリング結果確認 ===\")\n",
        "                print(f\"レンダリング画像数: {len(render_images)}\")\n",
        "\n",
        "                # Colab用画像グリッド表示\n",
        "                fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "                axes = axes.flatten()\n",
        "\n",
        "                for i, img_path in enumerate(render_images):\n",
        "                    if i >= 6:  # Colab表示制限\n",
        "                        break\n",
        "                    try:\n",
        "                        img = Image.open(img_path)\n",
        "                        # Colab用リサイズ（メモリ節約）\n",
        "                        img.thumbnail((400, 400), Image.Resampling.LANCZOS)\n",
        "\n",
        "                        axes[i].imshow(img)\n",
        "                        axes[i].set_title(f'Render {i+1} (Colab)', fontsize=10)\n",
        "                        axes[i].axis('off')\n",
        "                    except Exception as e:\n",
        "                        axes[i].text(0.5, 0.5, f'Load Error\\n{e}',\n",
        "                                   ha='center', va='center', transform=axes[i].transAxes)\n",
        "                        axes[i].axis('off')\n",
        "\n",
        "                # 空のサブプロットを非表示\n",
        "                for i in range(len(render_images), 6):\n",
        "                    axes[i].axis('off')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig('/content/drive/MyDrive/processed/colab_render_samples.png', dpi=100, bbox_inches='tight')\n",
        "                plt.show()\n",
        "                print(\"Colab環境でのレンダリング結果表示が完了しました\")\n",
        "\n",
        "        # 5. Colab環境ファイルサイズ確認\n",
        "        print(f\"\\n=== Colab環境ファイルサイズ確認 ===\")\n",
        "        total_size = 0\n",
        "        file_types = {}\n",
        "\n",
        "        for root, dirs, files in os.walk(exp_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    size = os.path.getsize(file_path)\n",
        "                    total_size += size\n",
        "\n",
        "                    ext = os.path.splitext(file)[1].lower()\n",
        "                    if ext in file_types:\n",
        "                        file_types[ext] += size\n",
        "                    else:\n",
        "                        file_types[ext] = size\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        print(f\"合計サイズ: {total_size / (1024**3):.2f} GB\")\n",
        "        print(f\"ファイル種別サイズ:\")\n",
        "        for ext, size in sorted(file_types.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "            size_mb = size / (1024**2)\n",
        "            if size_mb > 1:\n",
        "                print(f\"  {ext if ext else 'no_ext'}: {size_mb:.1f} MB\")\n",
        "\n",
        "        # 6. Colab環境リソース使用状況\n",
        "        print(f\"\\n=== Colab リソース使用状況 ===\")\n",
        "\n",
        "        # GPU使用状況 (Colab環境)\n",
        "        try:\n",
        "            import torch\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                gpu_allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "                gpu_cached = torch.cuda.memory_reserved(0) / (1024**3)\n",
        "\n",
        "                print(f\"GPU総メモリ: {gpu_memory:.1f} GB\")\n",
        "                print(f\"GPU使用中: {gpu_allocated:.1f} GB ({gpu_allocated/gpu_memory*100:.1f}%)\")\n",
        "                print(f\"GPU予約済み: {gpu_cached:.1f} GB ({gpu_cached/gpu_memory*100:.1f}%)\")\n",
        "        except:\n",
        "            print(\"GPU情報の取得に失敗しました\")\n",
        "\n",
        "        # RAM使用状況 (Colab環境)\n",
        "        try:\n",
        "            import psutil\n",
        "            ram = psutil.virtual_memory()\n",
        "            print(f\"RAM総容量: {ram.total / (1024**3):.1f} GB\")\n",
        "            print(f\"RAM使用中: {ram.used / (1024**3):.1f} GB ({ram.percent:.1f}%)\")\n",
        "            print(f\"RAM利用可能: {ram.available / (1024**3):.1f} GB\")\n",
        "        except:\n",
        "            print(\"RAM情報の取得に失敗しました\")\n",
        "\n",
        "        print(f\"\\n✓ Google Colab環境での品質確認が完了しました\")\n",
        "        print(f\"画像は /content/drive/MyDrive/processed/ に保存されました（ダウンロード可能）\")\n",
        "\n",
        "    else:\n",
        "        print(\"実験ディレクトリが見つかりません\")\n",
        "        print(\"セル5でのColab学習を完了してから実行してください\")\n",
        "\n",
        "else:\n",
        "    print(\"outputs/ フォルダが見つかりません\")\n",
        "    print(\"セル5でのColab学習を完了してから実行してください\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68424e77",
      "metadata": {
        "id": "68424e77"
      },
      "outputs": [],
      "source": [
        "# 11. Google Colab ダウンロード＆アーカイブ作成\n",
        "print(\"=== Google Colab ダウンロード用ファイル準備 ===\")\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# Colab環境確認\n",
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if is_colab():\n",
        "    print(\"Google Colab環境を検出しました\")\n",
        "\n",
        "    # 1. Colab用ダウンロードディレクトリ作成\n",
        "    download_dir = \"/content/drive/MyDrive/processed/colab_downloads\"\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "    # 2. 各種エクスポートファイルを収集\n",
        "    files_to_download = []\n",
        "\n",
        "    # outputs/からの学習結果\n",
        "    outputs_dir = '/content/drive/MyDrive/processed/outputs'\n",
        "    if os.path.exists(outputs_dir):\n",
        "        print(\"\\n学習結果ファイルを収集中...\")\n",
        "\n",
        "        # 最新実験ディレクトリを特定\n",
        "        experiment_dirs = [d for d in os.listdir(outputs_dir)\n",
        "                          if os.path.isdir(os.path.join(outputs_dir, d))]\n",
        "\n",
        "        if experiment_dirs:\n",
        "            latest_exp = sorted(experiment_dirs)[-1]\n",
        "            exp_dir = os.path.join(outputs_dir, latest_exp)\n",
        "\n",
        "            # 重要ファイルのみを選択的に収集（Colabサイズ制限対応）\n",
        "            important_files = [\n",
        "                ('config.yml', 'Config'),\n",
        "                ('*.ckpt', 'Checkpoint'),\n",
        "                ('**/cameras.json', 'Cameras'),\n",
        "                ('**/dataparser_transforms.json', 'Transforms'),\n",
        "                ('**/point_cloud.ply', 'PointCloud'),\n",
        "                ('**/*.splat', 'GaussianSplat')\n",
        "            ]\n",
        "\n",
        "            for pattern, file_type in important_files:\n",
        "                import glob\n",
        "                matches = glob.glob(os.path.join(exp_dir, pattern), recursive=True)\n",
        "                for match in matches[:3]:  # Colab用に各種類3ファイルまで\n",
        "                    if os.path.getsize(match) < 100 * 1024 * 1024:  # 100MB制限\n",
        "                        files_to_download.append((match, file_type))\n",
        "\n",
        "    # alternative_exportsからのファイル\n",
        "    alt_export_dir = \"/content/drive/MyDrive/processed/alternative_exports\"\n",
        "    if os.path.exists(alt_export_dir):\n",
        "        print(\"代替エクスポートファイルを収集中...\")\n",
        "        for root, dirs, files in os.walk(alt_export_dir):\n",
        "            for file in files[:10]:  # Colab用制限\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.getsize(file_path) < 50 * 1024 * 1024:  # 50MB制限\n",
        "                    files_to_download.append((file_path, \"Alternative\"))\n",
        "\n",
        "    # 3. Colab用ダウンロードアーカイブ作成\n",
        "    if files_to_download:\n",
        "        print(f\"\\n{len(files_to_download)} ファイルをアーカイブ中...\")\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        archive_name = f\"nerfstudio_colab_results_{timestamp}.zip\"\n",
        "        archive_path = os.path.join(download_dir, archive_name)\n",
        "\n",
        "        # ファイルサイズ確認\n",
        "        total_size = sum(os.path.getsize(file_path) for file_path, _ in files_to_download)\n",
        "        print(f\"アーカイブ対象サイズ: {total_size / (1024**2):.1f} MB\")\n",
        "\n",
        "        # Colabダウンロード制限チェック（500MB）\n",
        "        colab_limit = 500 * 1024 * 1024\n",
        "        if total_size > colab_limit:\n",
        "            print(f\"⚠️  サイズが大きいため、重要ファイルのみを選択します\")\n",
        "            # 重要度順にファイルを選択\n",
        "            priority_types = ['Config', 'Checkpoint', 'Cameras', 'Transforms']\n",
        "            selected_files = []\n",
        "            current_size = 0\n",
        "\n",
        "            for priority_type in priority_types:\n",
        "                for file_path, file_type in files_to_download:\n",
        "                    if file_type == priority_type:\n",
        "                        file_size = os.path.getsize(file_path)\n",
        "                        if current_size + file_size < colab_limit:\n",
        "                            selected_files.append((file_path, file_type))\n",
        "                            current_size += file_size\n",
        "\n",
        "            files_to_download = selected_files\n",
        "            print(f\"選択されたファイル数: {len(files_to_download)}\")\n",
        "            print(f\"最終サイズ: {current_size / (1024**2):.1f} MB\")\n",
        "\n",
        "        # ZIPアーカイブ作成\n",
        "        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file_path, file_type in files_to_download:\n",
        "                # Colab用のファイル名調整\n",
        "                arcname = f\"{file_type}/{os.path.basename(file_path)}\"\n",
        "                zipf.write(file_path, arcname)\n",
        "                print(f\"  ✓ {file_type}: {os.path.basename(file_path)}\")\n",
        "\n",
        "            # Colab環境情報を追加\n",
        "            colab_info = {\n",
        "                \"creation_date\": datetime.now().isoformat(),\n",
        "                \"environment\": \"Google Colab\",\n",
        "                \"total_files\": len(files_to_download),\n",
        "                \"archive_size_mb\": os.path.getsize(archive_path) / (1024**2),\n",
        "                \"file_types\": list(set(file_type for _, file_type in files_to_download)),\n",
        "                \"download_instructions\": \"Extract and use with local nerfstudio installation\"\n",
        "            }\n",
        "\n",
        "            info_json = json.dumps(colab_info, indent=2)\n",
        "            zipf.writestr(\"colab_export_info.json\", info_json)\n",
        "\n",
        "        # 4. Colab追加ファイルの準備\n",
        "        additional_files = []\n",
        "\n",
        "        # 可視化画像があれば追加\n",
        "        viz_files = [\n",
        "            \"/content/drive/MyDrive/processed/colab_training_metrics.png\",\n",
        "            \"/content/drive/MyDrive/processed/colab_render_samples.png\"\n",
        "        ]\n",
        "\n",
        "        for viz_file in viz_files:\n",
        "            if os.path.exists(viz_file):\n",
        "                additional_files.append(viz_file)\n",
        "\n",
        "        # 5. Colabダウンロード実行\n",
        "        print(f\"\\n=== Google Colab ダウンロード開始 ===\")\n",
        "\n",
        "        try:\n",
        "            # メインアーカイブをダウンロード\n",
        "            archive_size_mb = os.path.getsize(archive_path) / (1024**2)\n",
        "            print(f\"メインアーカイブ: {archive_name} ({archive_size_mb:.1f} MB)\")\n",
        "            files.download(archive_path)\n",
        "            print(f\"✓ {archive_name} のダウンロードが完了しました\")\n",
        "\n",
        "            # 追加ファイルをダウンロード\n",
        "            for additional_file in additional_files:\n",
        "                try:\n",
        "                    files.download(additional_file)\n",
        "                    print(f\"✓ {os.path.basename(additional_file)} のダウンロードが完了しました\")\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️  {os.path.basename(additional_file)} のダウンロードに失敗: {e}\")\n",
        "\n",
        "            print(f\"\\n=== ダウンロード完了 ===\")\n",
        "            print(f\"ローカル環境での使用方法:\")\n",
        "            print(f\"1. {archive_name} を解凍\")\n",
        "            print(f\"2. 各フォルダの説明:\")\n",
        "            print(f\"   - Config/: nerfstudio設定ファイル\")\n",
        "            print(f\"   - Checkpoint/: 学習済みモデル\")\n",
        "            print(f\"   - Cameras/: カメラパラメータ\")\n",
        "            print(f\"   - Transforms/: 座標変換情報\")\n",
        "            print(f\"   - PointCloud/: 3D点群データ\")\n",
        "            print(f\"   - GaussianSplat/: Gaussian Splatting用\")\n",
        "            print(f\"3. ローカルnerfstudioでの読み込み・レンダリング\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ダウンロードエラー: {e}\")\n",
        "            print(f\"ファイルは {download_dir} に保存されています\")\n",
        "\n",
        "    else:\n",
        "        print(\"ダウンロード可能なファイルが見つかりません\")\n",
        "        print(\"セル5での学習を完了してから実行してください\")\n",
        "\n",
        "else:\n",
        "    print(\"このセルはGoogle Colab環境でのみ動作します\")\n",
        "    print(\"ローカル環境では手動でファイルをコピーしてください\")\n",
        "\n",
        "print(f\"\\nGoogle Colab ダウンロード処理が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOretpdKOZOc"
      },
      "id": "NOretpdKOZOc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}